CROSS VALIDATION 0
Loss at the end of iteration 0: 10.8357968542
Loss at the end of iteration 1: 2.20006422157
Loss at the end of iteration 2: 9.54747393945
Loss at the end of iteration 3: 0.309777904382
Loss at the end of iteration 4: 0.303400441765
Loss at the end of iteration 5: 0.297154273307
Loss at the end of iteration 6: 0.291036696027
Loss at the end of iteration 7: 0.285045062593
Loss at the end of iteration 8: 0.279176780171
Loss at the end of iteration 9: 0.273429309309
Loss at the end of iteration 10: 0.267800162833
Loss at the end of iteration 11: 0.262286904776
Loss at the end of iteration 12: 0.256887149317
Loss at the end of iteration 13: 0.251598559755
Loss at the end of iteration 14: 0.246418847494
Loss at the end of iteration 15: 0.241345771055
Loss at the end of iteration 16: 0.236377135103
Loss at the end of iteration 17: 0.231510789501
Loss at the end of iteration 18: 0.226744628375
Loss at the end of iteration 19: 0.222076589207
Loss at the end of iteration 20: 0.217504651939
Loss at the end of iteration 21: 0.213026838101
Loss at the end of iteration 22: 0.208641209955
Loss at the end of iteration 23: 0.204345869654
Loss at the end of iteration 24: 0.200138958424
Loss at the end of iteration 25: 0.196018655757
Loss at the end of iteration 26: 0.191983178625
Loss at the end of iteration 27: 0.188030780705
Loss at the end of iteration 28: 0.184159751629
Loss at the end of iteration 29: 0.18036841624
Loss at the end of iteration 30: 0.176655133867
Loss at the end of iteration 31: 0.173018297616
Loss at the end of iteration 32: 0.169456333675
Loss at the end of iteration 33: 0.165967700632
Loss at the end of iteration 34: 0.162550888808
Loss at the end of iteration 35: 0.159204419605
Loss at the end of iteration 36: 0.155926844865
Loss at the end of iteration 37: 0.152716746242
Loss at the end of iteration 38: 0.149572734592
Loss at the end of iteration 39: 0.146493449369
Loss at the end of iteration 40: 0.143477558036
Loss at the end of iteration 41: 0.14052375549
Loss at the end of iteration 42: 0.137630763495
Loss at the end of iteration 43: 0.134797330133
Loss at the end of iteration 44: 0.132022229257
Loss at the end of iteration 45: 0.129304259964
Loss at the end of iteration 46: 0.126642246074
Loss at the end of iteration 47: 0.124035035622
Loss at the end of iteration 48: 0.121481500358
Loss at the end of iteration 49: 0.118980535259
Loss at the end of iteration 50: 0.116531058053
Loss at the end of iteration 51: 0.114132008747
Loss at the end of iteration 52: 0.111782349171
Loss at the end of iteration 53: 0.10948106253
Loss at the end of iteration 54: 0.107227152959
Loss at the end of iteration 55: 0.105019645097
Loss at the end of iteration 56: 0.102857583661
Loss at the end of iteration 57: 0.100740033037
Loss at the end of iteration 58: 0.0986660768714
Loss at the end of iteration 59: 0.0966348176759
Loss at the end of iteration 60: 0.094645376439
Loss at the end of iteration 61: 0.0926968922456
Loss at the end of iteration 62: 0.0907885219046
Loss at the end of iteration 63: 0.0889194395835
Loss at the end of iteration 64: 0.0870888364518
Loss at the end of iteration 65: 0.0852959203303
Loss at the end of iteration 66: 0.0835399153486
Loss at the end of iteration 67: 0.0818200616093
Loss at the end of iteration 68: 0.0801356148593
Loss at the end of iteration 69: 0.0784858461674
Loss at the end of iteration 70: 0.0768700416093
Loss at the end of iteration 71: 0.0752875019581
Loss at the end of iteration 72: 0.0737375423822
Loss at the end of iteration 73: 0.0722194921488
Loss at the end of iteration 74: 0.0707326943337
Loss at the end of iteration 75: 0.0692765055366
Loss at the end of iteration 76: 0.0678502956034
Loss at the end of iteration 77: 0.0664534473529
Loss at the end of iteration 78: 0.0650853563099
Loss at the end of iteration 79: 0.0637454304439
Loss at the end of iteration 80: 0.0624330899124
Loss at the end of iteration 81: 0.0611477668104
Loss at the end of iteration 82: 0.0598889049244
Loss at the end of iteration 83: 0.0586559594917
Loss at the end of iteration 84: 0.057448396965
Loss at the end of iteration 85: 0.056265694781
Loss at the end of iteration 86: 0.0551073411346
Loss at the end of iteration 87: 0.0539728347574
Loss at the end of iteration 88: 0.0528616847007
Loss at the end of iteration 89: 0.0517734101231
Loss at the end of iteration 90: 0.0507075400821
Loss at the end of iteration 91: 0.049663613331
Loss at the end of iteration 92: 0.0486411781186
Loss at the end of iteration 93: 0.0476397919941
Loss at the end of iteration 94: 0.0466590216156
Loss at the end of iteration 95: 0.0456984425623
Loss at the end of iteration 96: 0.0447576391513
Loss at the end of iteration 97: 0.0438362042572
Loss at the end of iteration 98: 0.0429337391362
Loss at the end of iteration 99: 0.0420498532538
CROSS VALIDATION 1
Loss at the end of iteration 0: 10.8357968542
Loss at the end of iteration 1: 2.20006422157
Loss at the end of iteration 2: 9.54747393945
Loss at the end of iteration 3: 0.309777904382
Loss at the end of iteration 4: 0.303400441765
Loss at the end of iteration 5: 0.297154273307
Loss at the end of iteration 6: 0.291036696027
Loss at the end of iteration 7: 0.285045062593
Loss at the end of iteration 8: 0.279176780171
Loss at the end of iteration 9: 0.273429309309
Loss at the end of iteration 10: 0.267800162833
Loss at the end of iteration 11: 0.262286904776
Loss at the end of iteration 12: 0.256887149317
Loss at the end of iteration 13: 0.251598559755
Loss at the end of iteration 14: 0.246418847494
Loss at the end of iteration 15: 0.241345771055
Loss at the end of iteration 16: 0.236377135103
Loss at the end of iteration 17: 0.231510789501
Loss at the end of iteration 18: 0.226744628375
Loss at the end of iteration 19: 0.222076589207
Loss at the end of iteration 20: 0.217504651939
Loss at the end of iteration 21: 0.213026838101
Loss at the end of iteration 22: 0.208641209955
Loss at the end of iteration 23: 0.204345869654
Loss at the end of iteration 24: 0.200138958424
Loss at the end of iteration 25: 0.196018655757
Loss at the end of iteration 26: 0.191983178625
Loss at the end of iteration 27: 0.188030780705
Loss at the end of iteration 28: 0.184159751629
Loss at the end of iteration 29: 0.18036841624
Loss at the end of iteration 30: 0.176655133867
Loss at the end of iteration 31: 0.173018297616
Loss at the end of iteration 32: 0.169456333675
Loss at the end of iteration 33: 0.165967700632
Loss at the end of iteration 34: 0.162550888808
Loss at the end of iteration 35: 0.159204419605
Loss at the end of iteration 36: 0.155926844865
Loss at the end of iteration 37: 0.152716746242
Loss at the end of iteration 38: 0.149572734592
Loss at the end of iteration 39: 0.146493449369
Loss at the end of iteration 40: 0.143477558036
Loss at the end of iteration 41: 0.14052375549
Loss at the end of iteration 42: 0.137630763495
Loss at the end of iteration 43: 0.134797330133
Loss at the end of iteration 44: 0.132022229257
Loss at the end of iteration 45: 0.129304259964
Loss at the end of iteration 46: 0.126642246074
Loss at the end of iteration 47: 0.124035035622
Loss at the end of iteration 48: 0.121481500358
Loss at the end of iteration 49: 0.118980535259
Loss at the end of iteration 50: 0.116531058053
Loss at the end of iteration 51: 0.114132008747
Loss at the end of iteration 52: 0.111782349171
Loss at the end of iteration 53: 0.10948106253
Loss at the end of iteration 54: 0.107227152959
Loss at the end of iteration 55: 0.105019645097
Loss at the end of iteration 56: 0.102857583661
Loss at the end of iteration 57: 0.100740033037
Loss at the end of iteration 58: 0.0986660768714
Loss at the end of iteration 59: 0.0966348176759
Loss at the end of iteration 60: 0.094645376439
Loss at the end of iteration 61: 0.0926968922456
Loss at the end of iteration 62: 0.0907885219046
Loss at the end of iteration 63: 0.0889194395835
Loss at the end of iteration 64: 0.0870888364518
Loss at the end of iteration 65: 0.0852959203303
Loss at the end of iteration 66: 0.0835399153486
Loss at the end of iteration 67: 0.0818200616093
Loss at the end of iteration 68: 0.0801356148593
Loss at the end of iteration 69: 0.0784858461674
Loss at the end of iteration 70: 0.0768700416093
Loss at the end of iteration 71: 0.0752875019581
Loss at the end of iteration 72: 0.0737375423822
Loss at the end of iteration 73: 0.0722194921488
Loss at the end of iteration 74: 0.0707326943337
Loss at the end of iteration 75: 0.0692765055366
Loss at the end of iteration 76: 0.0678502956034
Loss at the end of iteration 77: 0.0664534473529
Loss at the end of iteration 78: 0.0650853563099
Loss at the end of iteration 79: 0.0637454304439
Loss at the end of iteration 80: 0.0624330899124
Loss at the end of iteration 81: 0.0611477668104
Loss at the end of iteration 82: 0.0598889049244
Loss at the end of iteration 83: 0.0586559594917
Loss at the end of iteration 84: 0.057448396965
Loss at the end of iteration 85: 0.056265694781
Loss at the end of iteration 86: 0.0551073411346
Loss at the end of iteration 87: 0.0539728347574
Loss at the end of iteration 88: 0.0528616847007
Loss at the end of iteration 89: 0.0517734101231
Loss at the end of iteration 90: 0.0507075400821
Loss at the end of iteration 91: 0.049663613331
Loss at the end of iteration 92: 0.0486411781186
Loss at the end of iteration 93: 0.0476397919941
Loss at the end of iteration 94: 0.0466590216156
Loss at the end of iteration 95: 0.0456984425623
Loss at the end of iteration 96: 0.0447576391513
Loss at the end of iteration 97: 0.0438362042572
Loss at the end of iteration 98: 0.0429337391362
Loss at the end of iteration 99: 0.0420498532538
CROSS VALIDATION 2
Loss at the end of iteration 0: 17.8471890714
Loss at the end of iteration 1: 0.285462929462
Loss at the end of iteration 2: 0.279586044327
Loss at the end of iteration 3: 0.273830147858
Loss at the end of iteration 4: 0.268192749236
Loss at the end of iteration 5: 0.26267140892
Loss at the end of iteration 6: 0.257263737593
Loss at the end of iteration 7: 0.25196739513
Loss at the end of iteration 8: 0.246780089578
Loss at the end of iteration 9: 0.241699576172
Loss at the end of iteration 10: 0.236723656361
Loss at the end of iteration 11: 0.231850176852
Loss at the end of iteration 12: 0.227077028688
Loss at the end of iteration 13: 0.222402146325
Loss at the end of iteration 14: 0.217823506744
Loss at the end of iteration 15: 0.213339128576
Loss at the end of iteration 16: 0.20894707124
Loss at the end of iteration 17: 0.204645434109
Loss at the end of iteration 18: 0.200432355683
Loss at the end of iteration 19: 0.196306012785
Loss at the end of iteration 20: 0.192264619773
Loss at the end of iteration 21: 0.188306427766
Loss at the end of iteration 22: 0.184429723886
Loss at the end of iteration 23: 0.180632830522
Loss at the end of iteration 24: 0.176914104597
Loss at the end of iteration 25: 0.173271936861
Loss at the end of iteration 26: 0.169704751196
Loss at the end of iteration 27: 0.166211003929
Loss at the end of iteration 28: 0.162789183169
Loss at the end of iteration 29: 0.15943780815
Loss at the end of iteration 30: 0.156155428591
Loss at the end of iteration 31: 0.152940624067
Loss at the end of iteration 32: 0.149792003398
Loss at the end of iteration 33: 0.146708204042
Loss at the end of iteration 34: 0.143687891509
Loss at the end of iteration 35: 0.140729758783
Loss at the end of iteration 36: 0.137832525756
Loss at the end of iteration 37: 0.134994938672
Loss at the end of iteration 38: 0.132215769587
Loss at the end of iteration 39: 0.129493815839
Loss at the end of iteration 40: 0.126827899523
Loss at the end of iteration 41: 0.124216866984
Loss at the end of iteration 42: 0.12165958832
Loss at the end of iteration 43: 0.119154956887
Loss at the end of iteration 44: 0.116701888826
Loss at the end of iteration 45: 0.114299322591
Loss at the end of iteration 46: 0.111946218491
Loss at the end of iteration 47: 0.109641558237
Loss at the end of iteration 48: 0.107384344507
Loss at the end of iteration 49: 0.10517360051
Loss at the end of iteration 50: 0.103008369562
Loss at the end of iteration 51: 0.100887714677
Loss at the end of iteration 52: 0.0988107181583
Loss at the end of iteration 53: 0.0967764812023
Loss at the end of iteration 54: 0.0947841235087
Loss at the end of iteration 55: 0.0928327829003
Loss at the end of iteration 56: 0.0909216149499
Loss at the end of iteration 57: 0.0890497926144
Loss at the end of iteration 58: 0.0872165058775
Loss at the end of iteration 59: 0.0854209613988
Loss at the end of iteration 60: 0.0836623821704
Loss at the end of iteration 61: 0.0819400071811
Loss at the end of iteration 62: 0.0802530910864
Loss at the end of iteration 63: 0.0786009038869
Loss at the end of iteration 64: 0.0769827306113
Loss at the end of iteration 65: 0.075397871008
Loss at the end of iteration 66: 0.0738456392414
Loss at the end of iteration 67: 0.0723253635953
Loss at the end of iteration 68: 0.0708363861825
Loss at the end of iteration 69: 0.0693780626597
Loss at the end of iteration 70: 0.0679497619487
Loss at the end of iteration 71: 0.0665508659637
Loss at the end of iteration 72: 0.0651807693434
Loss at the end of iteration 73: 2.54427453732
Loss at the end of iteration 74: 3.46264237518
Loss at the end of iteration 75: 0.130289176269
Loss at the end of iteration 76: 0.127606885701
Loss at the end of iteration 77: 0.124979816011
Loss at the end of iteration 78: 0.122406830355
Loss at the end of iteration 79: 0.119886815294
Loss at the end of iteration 80: 0.11741868031
Loss at the end of iteration 81: 0.115001357339
Loss at the end of iteration 82: 0.112633800302
Loss at the end of iteration 83: 0.110314984658
Loss at the end of iteration 84: 0.108043906957
Loss at the end of iteration 85: 0.105819584409
Loss at the end of iteration 86: 0.103641054455
Loss at the end of iteration 87: 0.101507374354
Loss at the end of iteration 88: 0.099417620772
Loss at the end of iteration 89: 0.0973708893847
Loss at the end of iteration 90: 0.0953662944853
Loss at the end of iteration 91: 0.0934029686011
Loss at the end of iteration 92: 0.0914800621182
Loss at the end of iteration 93: 0.0895967429139
Loss at the end of iteration 94: 0.0877521959966
Loss at the end of iteration 95: 0.0859456231532
Loss at the end of iteration 96: 0.0841762426033
Loss at the end of iteration 97: 0.0824432886616
Loss at the end of iteration 98: 0.0807460114057
Loss at the end of iteration 99: 0.0790836763522
CROSS VALIDATION 3
Loss at the end of iteration 0: 36.3881365374
Loss at the end of iteration 1: 0.305667184827
Loss at the end of iteration 2: 0.299374350454
Loss at the end of iteration 3: 0.293211067981
Loss at the end of iteration 4: 0.287174670295
Loss at the end of iteration 5: 0.281262545194
Loss at the end of iteration 6: 0.27547213425
Loss at the end of iteration 7: 0.26980093171
Loss at the end of iteration 8: 0.264246483404
Loss at the end of iteration 9: 0.258806385689
Loss at the end of iteration 10: 0.253478284406
Loss at the end of iteration 11: 0.24825987386
Loss at the end of iteration 12: 0.243148895826
Loss at the end of iteration 13: 0.238143138567
Loss at the end of iteration 14: 0.233240435881
Loss at the end of iteration 15: 0.228438666162
Loss at the end of iteration 16: 0.223735751483
Loss at the end of iteration 17: 0.219129656694
Loss at the end of iteration 18: 0.214618388543
Loss at the end of iteration 19: 0.210199994815
Loss at the end of iteration 20: 0.205872563483
Loss at the end of iteration 21: 0.201634221888
Loss at the end of iteration 22: 0.197483135919
Loss at the end of iteration 23: 0.193417509226
Loss at the end of iteration 24: 0.189435582442
Loss at the end of iteration 25: 0.185535632418
Loss at the end of iteration 26: 0.181715971483
Loss at the end of iteration 27: 0.177974946708
Loss at the end of iteration 28: 0.174310939194
Loss at the end of iteration 29: 0.17072236337
Loss at the end of iteration 30: 0.167207666308
Loss at the end of iteration 31: 0.163765327051
Loss at the end of iteration 32: 0.160393855953
Loss at the end of iteration 33: 0.157091794038
Loss at the end of iteration 34: 0.153857712362
Loss at the end of iteration 35: 0.150690211404
Loss at the end of iteration 36: 0.147587920452
Loss at the end of iteration 37: 0.144549497013
Loss at the end of iteration 38: 0.141573626234
Loss at the end of iteration 39: 0.138659020331
Loss at the end of iteration 40: 0.135804418029
Loss at the end of iteration 41: 0.133008584024
Loss at the end of iteration 42: 0.130270308439
Loss at the end of iteration 43: 0.127588406307
Loss at the end of iteration 44: 0.124961717056
Loss at the end of iteration 45: 0.122389104007
Loss at the end of iteration 46: 0.119869453881
Loss at the end of iteration 47: 0.117401676321
Loss at the end of iteration 48: 0.114984703415
Loss at the end of iteration 49: 0.112617489236
Loss at the end of iteration 50: 0.110299009391
Loss at the end of iteration 51: 0.108028260576
Loss at the end of iteration 52: 0.105804260144
Loss at the end of iteration 53: 0.103626045673
Loss at the end of iteration 54: 0.101492674561
Loss at the end of iteration 55: 0.0994032236068
Loss at the end of iteration 56: 0.097356788617
Loss at the end of iteration 57: 0.095352484013
Loss at the end of iteration 58: 0.0933894424479
Loss at the end of iteration 59: 0.0914668144307
Loss at the end of iteration 60: 0.0895837679593
Loss at the end of iteration 61: 0.0877394881602
Loss at the end of iteration 62: 0.0859331769356
Loss at the end of iteration 63: 0.0841640526187
Loss at the end of iteration 64: 0.0824313496347
Loss at the end of iteration 65: 0.08073431817
Loss at the end of iteration 66: 0.0790722238477
Loss at the end of iteration 67: 0.0774443474093
Loss at the end of iteration 68: 0.0758499844043
Loss at the end of iteration 69: 0.0742884448845
Loss at the end of iteration 70: 0.0727590531059
Loss at the end of iteration 71: 0.0712611472363
Loss at the end of iteration 72: 0.0697940790686
Loss at the end of iteration 73: 0.0683572137406
Loss at the end of iteration 74: 0.0669499294602
Loss at the end of iteration 75: 0.0655716172361
Loss at the end of iteration 76: 0.0642216806146
Loss at the end of iteration 77: 0.062899535421
Loss at the end of iteration 78: 0.0616046095076
Loss at the end of iteration 79: 0.0603363425052
Loss at the end of iteration 80: 0.0590941855813
Loss at the end of iteration 81: 0.0578776012023
Loss at the end of iteration 82: 0.0566860629007
Loss at the end of iteration 83: 0.0555190550478
Loss at the end of iteration 84: 0.0543760726301
Loss at the end of iteration 85: 0.0532566210308
Loss at the end of iteration 86: 0.0521602158162
Loss at the end of iteration 87: 0.0510863825254
Loss at the end of iteration 88: 0.0500346564655
Loss at the end of iteration 89: 0.0490045825104
Loss at the end of iteration 90: 0.0479957149035
Loss at the end of iteration 91: 0.0470076170655
Loss at the end of iteration 92: 0.0460398614047
Loss at the end of iteration 93: 0.0450920291324
Loss at the end of iteration 94: 0.0441637100817
Loss at the end of iteration 95: 0.0432545025297
Loss at the end of iteration 96: 0.0423640130241
Loss at the end of iteration 97: 0.0414918562126
Loss at the end of iteration 98: 0.040637654676
Loss at the end of iteration 99: 0.0398010387654
CROSS VALIDATION 4
Loss at the end of iteration 0: 36.3881365374
Loss at the end of iteration 1: 0.305667184827
Loss at the end of iteration 2: 0.299374350454
Loss at the end of iteration 3: 0.293211067981
Loss at the end of iteration 4: 0.287174670295
Loss at the end of iteration 5: 0.281262545194
Loss at the end of iteration 6: 0.27547213425
Loss at the end of iteration 7: 0.26980093171
Loss at the end of iteration 8: 0.264246483404
Loss at the end of iteration 9: 0.258806385689
Loss at the end of iteration 10: 0.253478284406
Loss at the end of iteration 11: 0.24825987386
Loss at the end of iteration 12: 0.243148895826
Loss at the end of iteration 13: 0.238143138567
Loss at the end of iteration 14: 0.233240435881
Loss at the end of iteration 15: 0.228438666162
Loss at the end of iteration 16: 0.223735751483
Loss at the end of iteration 17: 0.219129656694
Loss at the end of iteration 18: 0.214618388543
Loss at the end of iteration 19: 0.210199994815
Loss at the end of iteration 20: 0.205872563483
Loss at the end of iteration 21: 0.201634221888
Loss at the end of iteration 22: 0.197483135919
Loss at the end of iteration 23: 0.193417509226
Loss at the end of iteration 24: 0.189435582442
Loss at the end of iteration 25: 0.185535632418
Loss at the end of iteration 26: 0.181715971483
Loss at the end of iteration 27: 0.177974946708
Loss at the end of iteration 28: 0.174310939194
Loss at the end of iteration 29: 0.17072236337
Loss at the end of iteration 30: 0.167207666308
Loss at the end of iteration 31: 0.163765327051
Loss at the end of iteration 32: 0.160393855953
Loss at the end of iteration 33: 0.157091794038
Loss at the end of iteration 34: 0.153857712362
Loss at the end of iteration 35: 0.150690211404
Loss at the end of iteration 36: 0.147587920452
Loss at the end of iteration 37: 0.144549497013
Loss at the end of iteration 38: 0.141573626234
Loss at the end of iteration 39: 0.138659020331
Loss at the end of iteration 40: 0.135804418029
Loss at the end of iteration 41: 0.133008584024
Loss at the end of iteration 42: 0.130270308439
Loss at the end of iteration 43: 0.127588406307
Loss at the end of iteration 44: 0.124961717056
Loss at the end of iteration 45: 0.122389104007
Loss at the end of iteration 46: 0.119869453881
Loss at the end of iteration 47: 0.117401676321
Loss at the end of iteration 48: 0.114984703415
Loss at the end of iteration 49: 0.112617489236
Loss at the end of iteration 50: 0.110299009391
Loss at the end of iteration 51: 0.108028260576
Loss at the end of iteration 52: 0.105804260144
Loss at the end of iteration 53: 0.103626045673
Loss at the end of iteration 54: 0.101492674561
Loss at the end of iteration 55: 0.0994032236068
Loss at the end of iteration 56: 0.097356788617
Loss at the end of iteration 57: 0.095352484013
Loss at the end of iteration 58: 0.0933894424479
Loss at the end of iteration 59: 0.0914668144307
Loss at the end of iteration 60: 0.0895837679593
Loss at the end of iteration 61: 0.0877394881602
Loss at the end of iteration 62: 0.0859331769356
Loss at the end of iteration 63: 0.0841640526187
Loss at the end of iteration 64: 0.0824313496347
Loss at the end of iteration 65: 0.08073431817
Loss at the end of iteration 66: 0.0790722238477
Loss at the end of iteration 67: 0.0774443474093
Loss at the end of iteration 68: 0.0758499844043
Loss at the end of iteration 69: 0.0742884448845
Loss at the end of iteration 70: 0.0727590531059
Loss at the end of iteration 71: 0.0712611472363
Loss at the end of iteration 72: 0.0697940790686
Loss at the end of iteration 73: 0.0683572137406
Loss at the end of iteration 74: 0.0669499294602
Loss at the end of iteration 75: 0.0655716172361
Loss at the end of iteration 76: 0.0642216806146
Loss at the end of iteration 77: 0.062899535421
Loss at the end of iteration 78: 0.0616046095076
Loss at the end of iteration 79: 0.0603363425052
Loss at the end of iteration 80: 0.0590941855813
Loss at the end of iteration 81: 0.0578776012023
Loss at the end of iteration 82: 0.0566860629007
Loss at the end of iteration 83: 0.0555190550478
Loss at the end of iteration 84: 0.0543760726301
Loss at the end of iteration 85: 0.0532566210308
Loss at the end of iteration 86: 0.0521602158162
Loss at the end of iteration 87: 0.0510863825254
Loss at the end of iteration 88: 0.0500346564655
Loss at the end of iteration 89: 0.0490045825104
Loss at the end of iteration 90: 0.0479957149035
Loss at the end of iteration 91: 0.0470076170655
Loss at the end of iteration 92: 0.0460398614047
Loss at the end of iteration 93: 0.0450920291324
Loss at the end of iteration 94: 0.0441637100817
Loss at the end of iteration 95: 0.0432545025297
Loss at the end of iteration 96: 0.0423640130241
Loss at the end of iteration 97: 0.0414918562126
Loss at the end of iteration 98: 0.040637654676
Loss at the end of iteration 99: 0.0487897778218
CROSS VALIDATION 5
Loss at the end of iteration 0: 36.3881365374
Loss at the end of iteration 1: 0.305667184827
Loss at the end of iteration 2: 0.299374350454
Loss at the end of iteration 3: 0.293211067981
Loss at the end of iteration 4: 0.287174670295
Loss at the end of iteration 5: 0.281262545194
Loss at the end of iteration 6: 0.27547213425
Loss at the end of iteration 7: 0.26980093171
Loss at the end of iteration 8: 0.264246483404
Loss at the end of iteration 9: 0.258806385689
Loss at the end of iteration 10: 0.253478284406
Loss at the end of iteration 11: 0.24825987386
Loss at the end of iteration 12: 0.243148895826
Loss at the end of iteration 13: 0.238143138567
Loss at the end of iteration 14: 0.233240435881
Loss at the end of iteration 15: 0.228438666162
Loss at the end of iteration 16: 0.223735751483
Loss at the end of iteration 17: 0.219129656694
Loss at the end of iteration 18: 0.214618388543
Loss at the end of iteration 19: 0.210199994815
Loss at the end of iteration 20: 0.205872563483
Loss at the end of iteration 21: 0.201634221888
Loss at the end of iteration 22: 0.197483135919
Loss at the end of iteration 23: 0.193417509226
Loss at the end of iteration 24: 0.189435582442
Loss at the end of iteration 25: 0.185535632418
Loss at the end of iteration 26: 0.181715971483
Loss at the end of iteration 27: 0.177974946708
Loss at the end of iteration 28: 0.174310939194
Loss at the end of iteration 29: 0.17072236337
Loss at the end of iteration 30: 0.167207666308
Loss at the end of iteration 31: 0.163765327051
Loss at the end of iteration 32: 0.160393855953
Loss at the end of iteration 33: 0.157091794038
Loss at the end of iteration 34: 0.153857712362
Loss at the end of iteration 35: 0.150690211404
Loss at the end of iteration 36: 0.147587920452
Loss at the end of iteration 37: 0.144549497013
Loss at the end of iteration 38: 0.141573626234
Loss at the end of iteration 39: 0.138659020331
Loss at the end of iteration 40: 0.135804418029
Loss at the end of iteration 41: 0.133008584024
Loss at the end of iteration 42: 0.130270308439
Loss at the end of iteration 43: 0.127588406307
Loss at the end of iteration 44: 0.124961717056
Loss at the end of iteration 45: 0.122389104007
Loss at the end of iteration 46: 0.119869453881
Loss at the end of iteration 47: 0.117401676321
Loss at the end of iteration 48: 0.114984703415
Loss at the end of iteration 49: 0.112617489236
Loss at the end of iteration 50: 0.110299009391
Loss at the end of iteration 51: 0.108028260576
Loss at the end of iteration 52: 0.105804260144
Loss at the end of iteration 53: 0.103626045673
Loss at the end of iteration 54: 0.101492674561
Loss at the end of iteration 55: 0.0994032236068
Loss at the end of iteration 56: 0.097356788617
Loss at the end of iteration 57: 0.095352484013
Loss at the end of iteration 58: 0.0933894424479
Loss at the end of iteration 59: 0.0914668144307
Loss at the end of iteration 60: 0.0895837679593
Loss at the end of iteration 61: 0.0877394881602
Loss at the end of iteration 62: 0.0859331769356
Loss at the end of iteration 63: 0.0841640526187
Loss at the end of iteration 64: 0.0824313496347
Loss at the end of iteration 65: 0.08073431817
Loss at the end of iteration 66: 0.0790722238477
Loss at the end of iteration 67: 0.0774443474093
Loss at the end of iteration 68: 0.0758499844043
Loss at the end of iteration 69: 0.0742884448845
Loss at the end of iteration 70: 0.0727590531059
Loss at the end of iteration 71: 0.0712611472363
Loss at the end of iteration 72: 0.0697940790686
Loss at the end of iteration 73: 0.0683572137406
Loss at the end of iteration 74: 0.0669499294602
Loss at the end of iteration 75: 0.0655716172361
Loss at the end of iteration 76: 0.0642216806146
Loss at the end of iteration 77: 0.062899535421
Loss at the end of iteration 78: 0.0616046095076
Loss at the end of iteration 79: 0.0603363425052
Loss at the end of iteration 80: 0.0590941855813
Loss at the end of iteration 81: 0.0578776012023
Loss at the end of iteration 82: 0.0566860629007
Loss at the end of iteration 83: 0.0555190550478
Loss at the end of iteration 84: 0.0543760726301
Loss at the end of iteration 85: 0.0532566210308
Loss at the end of iteration 86: 0.0521602158162
Loss at the end of iteration 87: 0.0510863825254
Loss at the end of iteration 88: 0.0500346564655
Loss at the end of iteration 89: 0.0490045825104
Loss at the end of iteration 90: 0.0479957149035
Loss at the end of iteration 91: 0.0470076170655
Loss at the end of iteration 92: 0.0460398614047
Loss at the end of iteration 93: 0.0450920291324
Loss at the end of iteration 94: 0.0441637100817
Loss at the end of iteration 95: 0.0432545025297
Loss at the end of iteration 96: 0.0423640130241
Loss at the end of iteration 97: 0.0414918562126
Loss at the end of iteration 98: 0.040637654676
Loss at the end of iteration 99: 0.0487897778218
CROSS VALIDATION 6
Loss at the end of iteration 0: 36.3881365374
Loss at the end of iteration 1: 0.305667184827
Loss at the end of iteration 2: 0.299374350454
Loss at the end of iteration 3: 0.293211067981
Loss at the end of iteration 4: 0.287174670295
Loss at the end of iteration 5: 0.281262545194
Loss at the end of iteration 6: 0.27547213425
Loss at the end of iteration 7: 0.26980093171
Loss at the end of iteration 8: 0.264246483404
Loss at the end of iteration 9: 0.258806385689
Loss at the end of iteration 10: 0.253478284406
Loss at the end of iteration 11: 0.24825987386
Loss at the end of iteration 12: 0.243148895826
Loss at the end of iteration 13: 0.238143138567
Loss at the end of iteration 14: 0.233240435881
Loss at the end of iteration 15: 0.228438666162
Loss at the end of iteration 16: 0.223735751483
Loss at the end of iteration 17: 0.219129656694
Loss at the end of iteration 18: 0.214618388543
Loss at the end of iteration 19: 0.210199994815
Loss at the end of iteration 20: 0.205872563483
Loss at the end of iteration 21: 0.201634221888
Loss at the end of iteration 22: 0.197483135919
Loss at the end of iteration 23: 0.193417509226
Loss at the end of iteration 24: 0.189435582442
Loss at the end of iteration 25: 0.185535632418
Loss at the end of iteration 26: 0.181715971483
Loss at the end of iteration 27: 0.177974946708
Loss at the end of iteration 28: 0.174310939194
Loss at the end of iteration 29: 0.17072236337
Loss at the end of iteration 30: 0.167207666308
Loss at the end of iteration 31: 0.163765327051
Loss at the end of iteration 32: 0.160393855953
Loss at the end of iteration 33: 0.157091794038
Loss at the end of iteration 34: 0.153857712362
Loss at the end of iteration 35: 0.150690211404
Loss at the end of iteration 36: 0.147587920452
Loss at the end of iteration 37: 0.144549497013
Loss at the end of iteration 38: 0.141573626234
Loss at the end of iteration 39: 0.138659020331
Loss at the end of iteration 40: 0.135804418029
Loss at the end of iteration 41: 0.133008584024
Loss at the end of iteration 42: 0.130270308439
Loss at the end of iteration 43: 0.127588406307
Loss at the end of iteration 44: 0.124961717056
Loss at the end of iteration 45: 0.122389104007
Loss at the end of iteration 46: 0.119869453881
Loss at the end of iteration 47: 0.117401676321
Loss at the end of iteration 48: 0.114984703415
Loss at the end of iteration 49: 0.112617489236
Loss at the end of iteration 50: 0.110299009391
Loss at the end of iteration 51: 0.108028260576
Loss at the end of iteration 52: 0.105804260144
Loss at the end of iteration 53: 0.103626045673
Loss at the end of iteration 54: 0.101492674561
Loss at the end of iteration 55: 0.0994032236068
Loss at the end of iteration 56: 0.097356788617
Loss at the end of iteration 57: 0.095352484013
Loss at the end of iteration 58: 0.0933894424479
Loss at the end of iteration 59: 0.0914668144307
Loss at the end of iteration 60: 0.0895837679593
Loss at the end of iteration 61: 0.0877394881602
Loss at the end of iteration 62: 0.0859331769356
Loss at the end of iteration 63: 0.0841640526187
Loss at the end of iteration 64: 0.0824313496347
Loss at the end of iteration 65: 0.08073431817
Loss at the end of iteration 66: 0.0790722238477
Loss at the end of iteration 67: 0.0774443474093
Loss at the end of iteration 68: 0.0758499844043
Loss at the end of iteration 69: 0.0742884448845
Loss at the end of iteration 70: 0.0727590531059
Loss at the end of iteration 71: 0.0712611472363
Loss at the end of iteration 72: 0.0697940790686
Loss at the end of iteration 73: 0.0683572137406
Loss at the end of iteration 74: 0.0669499294602
Loss at the end of iteration 75: 0.0655716172361
Loss at the end of iteration 76: 0.0642216806146
Loss at the end of iteration 77: 0.062899535421
Loss at the end of iteration 78: 0.0616046095076
Loss at the end of iteration 79: 0.0603363425052
Loss at the end of iteration 80: 0.0590941855813
Loss at the end of iteration 81: 0.0578776012023
Loss at the end of iteration 82: 0.0566860629007
Loss at the end of iteration 83: 0.0555190550478
Loss at the end of iteration 84: 0.0543760726301
Loss at the end of iteration 85: 0.0532566210308
Loss at the end of iteration 86: 0.0521602158162
Loss at the end of iteration 87: 0.0510863825254
Loss at the end of iteration 88: 0.0500346564655
Loss at the end of iteration 89: 0.0490045825104
Loss at the end of iteration 90: 0.0479957149035
Loss at the end of iteration 91: 0.0470076170655
Loss at the end of iteration 92: 0.0460398614047
Loss at the end of iteration 93: 0.0450920291324
Loss at the end of iteration 94: 0.0441637100817
Loss at the end of iteration 95: 0.0432545025297
Loss at the end of iteration 96: 0.0423640130241
Loss at the end of iteration 97: 0.0414918562126
Loss at the end of iteration 98: 0.040637654676
Loss at the end of iteration 99: 0.0487897778218
CROSS VALIDATION 7
Loss at the end of iteration 0: 36.3881365374
Loss at the end of iteration 1: 0.305667184827
Loss at the end of iteration 2: 0.299374350454
Loss at the end of iteration 3: 0.293211067981
Loss at the end of iteration 4: 0.287174670295
Loss at the end of iteration 5: 0.281262545194
Loss at the end of iteration 6: 0.27547213425
Loss at the end of iteration 7: 0.26980093171
Loss at the end of iteration 8: 0.264246483404
Loss at the end of iteration 9: 0.258806385689
Loss at the end of iteration 10: 0.253478284406
Loss at the end of iteration 11: 0.24825987386
Loss at the end of iteration 12: 0.243148895826
Loss at the end of iteration 13: 0.238143138567
Loss at the end of iteration 14: 0.233240435881
Loss at the end of iteration 15: 0.228438666162
Loss at the end of iteration 16: 0.223735751483
Loss at the end of iteration 17: 0.219129656694
Loss at the end of iteration 18: 0.214618388543
Loss at the end of iteration 19: 0.210199994815
Loss at the end of iteration 20: 0.205872563483
Loss at the end of iteration 21: 0.201634221888
Loss at the end of iteration 22: 0.197483135919
Loss at the end of iteration 23: 0.193417509226
Loss at the end of iteration 24: 0.189435582442
Loss at the end of iteration 25: 0.185535632418
Loss at the end of iteration 26: 0.181715971483
Loss at the end of iteration 27: 0.177974946708
Loss at the end of iteration 28: 0.174310939194
Loss at the end of iteration 29: 0.17072236337
Loss at the end of iteration 30: 0.167207666308
Loss at the end of iteration 31: 0.163765327051
Loss at the end of iteration 32: 0.160393855953
Loss at the end of iteration 33: 0.157091794038
Loss at the end of iteration 34: 0.153857712362
Loss at the end of iteration 35: 0.150690211404
Loss at the end of iteration 36: 0.147587920452
Loss at the end of iteration 37: 0.144549497013
Loss at the end of iteration 38: 0.141573626234
Loss at the end of iteration 39: 0.138659020331
Loss at the end of iteration 40: 0.135804418029
Loss at the end of iteration 41: 0.133008584024
Loss at the end of iteration 42: 0.130270308439
Loss at the end of iteration 43: 0.127588406307
Loss at the end of iteration 44: 0.124961717056
Loss at the end of iteration 45: 0.122389104007
Loss at the end of iteration 46: 0.119869453881
Loss at the end of iteration 47: 0.117401676321
Loss at the end of iteration 48: 0.114984703415
Loss at the end of iteration 49: 0.112617489236
Loss at the end of iteration 50: 0.110299009391
Loss at the end of iteration 51: 0.108028260576
Loss at the end of iteration 52: 0.105804260144
Loss at the end of iteration 53: 0.103626045673
Loss at the end of iteration 54: 0.101492674561
Loss at the end of iteration 55: 0.0994032236068
Loss at the end of iteration 56: 0.097356788617
Loss at the end of iteration 57: 0.095352484013
Loss at the end of iteration 58: 0.0933894424479
Loss at the end of iteration 59: 0.0914668144307
Loss at the end of iteration 60: 0.0895837679593
Loss at the end of iteration 61: 0.0877394881602
Loss at the end of iteration 62: 0.0859331769356
Loss at the end of iteration 63: 0.0841640526187
Loss at the end of iteration 64: 0.0824313496347
Loss at the end of iteration 65: 0.08073431817
Loss at the end of iteration 66: 0.0790722238477
Loss at the end of iteration 67: 0.0774443474093
Loss at the end of iteration 68: 0.0758499844043
Loss at the end of iteration 69: 0.0742884448845
Loss at the end of iteration 70: 0.0727590531059
Loss at the end of iteration 71: 0.0712611472363
Loss at the end of iteration 72: 0.0697940790686
Loss at the end of iteration 73: 0.0683572137406
Loss at the end of iteration 74: 0.0669499294602
Loss at the end of iteration 75: 0.0655716172361
Loss at the end of iteration 76: 0.0642216806146
Loss at the end of iteration 77: 0.062899535421
Loss at the end of iteration 78: 0.0616046095076
Loss at the end of iteration 79: 0.0603363425052
Loss at the end of iteration 80: 0.0590941855813
Loss at the end of iteration 81: 0.0578776012023
Loss at the end of iteration 82: 0.0566860629007
Loss at the end of iteration 83: 0.0555190550478
Loss at the end of iteration 84: 0.0543760726301
Loss at the end of iteration 85: 0.0532566210308
Loss at the end of iteration 86: 0.0521602158162
Loss at the end of iteration 87: 0.0510863825254
Loss at the end of iteration 88: 0.0500346564655
Loss at the end of iteration 89: 0.0490045825104
Loss at the end of iteration 90: 0.0479957149035
Loss at the end of iteration 91: 0.0470076170655
Loss at the end of iteration 92: 0.0460398614047
Loss at the end of iteration 93: 0.0450920291324
Loss at the end of iteration 94: 0.0441637100817
Loss at the end of iteration 95: 0.0432545025297
Loss at the end of iteration 96: 0.0423640130241
Loss at the end of iteration 97: 0.0414918562126
Loss at the end of iteration 98: 0.040637654676
Loss at the end of iteration 99: 0.0487897778218
CROSS VALIDATION 8
Loss at the end of iteration 0: 32.894310403
Loss at the end of iteration 1: 0.289129940989
Loss at the end of iteration 2: 0.28317756232
Loss at the end of iteration 3: 0.277347726517
Loss at the end of iteration 4: 0.271637910766
Loss at the end of iteration 5: 0.266045644188
Loss at the end of iteration 6: 0.260568506773
Loss at the end of iteration 7: 0.255204128334
Loss at the end of iteration 8: 0.249950187477
Loss at the end of iteration 9: 0.244804410602
Loss at the end of iteration 10: 0.239764570913
Loss at the end of iteration 11: 0.23482848746
Loss at the end of iteration 12: 0.229994024191
Loss at the end of iteration 13: 0.225259089031
Loss at the end of iteration 14: 0.220621632972
Loss at the end of iteration 15: 0.216079649193
Loss at the end of iteration 16: 0.211631172185
Loss at the end of iteration 17: 0.207274276906
Loss at the end of iteration 18: 0.203007077942
Loss at the end of iteration 19: 0.198827728698
Loss at the end of iteration 20: 0.194734420592
Loss at the end of iteration 21: 0.190725382277
Loss at the end of iteration 22: 0.186798878875
Loss at the end of iteration 23: 0.18295321122
Loss at the end of iteration 24: 0.179186715131
Loss at the end of iteration 25: 0.175497760686
Loss at the end of iteration 26: 0.17188475152
Loss at the end of iteration 27: 0.16834612413
Loss at the end of iteration 28: 0.164880347203
Loss at the end of iteration 29: 0.161485920952
Loss at the end of iteration 30: 0.158161376465
Loss at the end of iteration 31: 0.154905275072
Loss at the end of iteration 32: 0.151716207721
Loss at the end of iteration 33: 0.148592794368
Loss at the end of iteration 34: 0.145533683379
Loss at the end of iteration 35: 0.142537550949
Loss at the end of iteration 36: 0.139603100526
Loss at the end of iteration 37: 0.136729062248
Loss at the end of iteration 38: 0.133914192398
Loss at the end of iteration 39: 0.131157272864
Loss at the end of iteration 40: 0.128457110609
Loss at the end of iteration 41: 0.125812537161
Loss at the end of iteration 42: 0.1232224081
Loss at the end of iteration 43: 0.120685602569
Loss at the end of iteration 44: 0.118201022784
Loss at the end of iteration 45: 0.115767593565
Loss at the end of iteration 46: 0.113384261862
Loss at the end of iteration 47: 0.111049996309
Loss at the end of iteration 48: 0.108763786769
Loss at the end of iteration 49: 0.106524643905
Loss at the end of iteration 50: 0.104331598743
Loss at the end of iteration 51: 0.102183702262
Loss at the end of iteration 52: 0.100080024976
Loss at the end of iteration 53: 0.0980196565342
Loss at the end of iteration 54: 0.0960017053295
Loss at the end of iteration 55: 0.0940252981092
Loss at the end of iteration 56: 0.0920895795983
Loss at the end of iteration 57: 0.0901937121299
Loss at the end of iteration 58: 0.0883368752823
Loss at the end of iteration 59: 0.0865182655239
Loss at the end of iteration 60: 0.0847370958656
Loss at the end of iteration 61: 0.0829925955203
Loss at the end of iteration 62: 0.081284009569
Loss at the end of iteration 63: 0.0796105986346
Loss at the end of iteration 64: 0.0779716385618
Loss at the end of iteration 65: 0.0763664201033
Loss at the end of iteration 66: 0.0747942486135
Loss at the end of iteration 67: 0.0732544437476
Loss at the end of iteration 68: 0.0717463391671
Loss at the end of iteration 69: 0.0702692822515
Loss at the end of iteration 70: 0.068822633816
Loss at the end of iteration 71: 0.067405767835
Loss at the end of iteration 72: 0.0660180711708
Loss at the end of iteration 73: 0.0646589433085
Loss at the end of iteration 74: 0.0633277960963
Loss at the end of iteration 75: 0.0620240534906
Loss at the end of iteration 76: 0.0607471513071
Loss at the end of iteration 77: 0.0594965369764
Loss at the end of iteration 78: 0.0582716693049
Loss at the end of iteration 79: 0.0570720182407
Loss at the end of iteration 80: 0.0558970646443
Loss at the end of iteration 81: 0.0547463000638
Loss at the end of iteration 82: 0.0536192265148
Loss at the end of iteration 83: 0.0525153562651
Loss at the end of iteration 84: 0.0514342116235
Loss at the end of iteration 85: 0.0503753247331
Loss at the end of iteration 86: 0.049338237369
Loss at the end of iteration 87: 0.0483225007397
Loss at the end of iteration 88: 0.0473276752932
Loss at the end of iteration 89: 0.0463533305266
Loss at the end of iteration 90: 0.0453990447998
Loss at the end of iteration 91: 0.0444644051532
Loss at the end of iteration 92: 0.0435490071288
Loss at the end of iteration 93: 0.0426524545954
Loss at the end of iteration 94: 0.0417743595767
Loss at the end of iteration 95: 0.0409143420842
Loss at the end of iteration 96: 0.040072029952
Loss at the end of iteration 97: 0.0392470586761
Loss at the end of iteration 98: 0.0384390712567
Loss at the end of iteration 99: 0.0376477180436
CROSS VALIDATION 9
Loss at the end of iteration 0: 37.3459534622
Loss at the end of iteration 1: 0.319399836831
Loss at the end of iteration 2: 0.312824285474
Loss at the end of iteration 3: 0.306384106371
Loss at the end of iteration 4: 0.300076512584
Loss at the end of iteration 5: 0.293898774552
Loss at the end of iteration 6: 0.287848218908
Loss at the end of iteration 7: 0.28192222732
Loss at the end of iteration 8: 0.276118235362
Loss at the end of iteration 9: 0.270433731402
Loss at the end of iteration 10: 0.264866255517
Loss at the end of iteration 11: 0.259413398424
Loss at the end of iteration 12: 0.254072800442
Loss at the end of iteration 13: 0.24884215047
Loss at the end of iteration 14: 0.243719184985
Loss at the end of iteration 15: 0.238701687064
Loss at the end of iteration 16: 0.233787485423
Loss at the end of iteration 17: 0.228974453481
Loss at the end of iteration 18: 0.224260508436
Loss at the end of iteration 19: 0.219643610365
Loss at the end of iteration 20: 0.215121761343
Loss at the end of iteration 21: 0.210693004573
Loss at the end of iteration 22: 0.206355423547
Loss at the end of iteration 23: 0.20210714121
Loss at the end of iteration 24: 0.197946319151
Loss at the end of iteration 25: 0.193871156808
Loss at the end of iteration 26: 0.189879890686
Loss at the end of iteration 27: 0.185970793596
Loss at the end of iteration 28: 0.182142173907
Loss at the end of iteration 29: 0.178392374813
Loss at the end of iteration 30: 0.174719773619
Loss at the end of iteration 31: 0.171122781035
Loss at the end of iteration 32: 0.16759984049
Loss at the end of iteration 33: 0.164149427461
Loss at the end of iteration 34: 0.160770048808
Loss at the end of iteration 35: 0.157460242131
Loss at the end of iteration 36: 0.154218575138
Loss at the end of iteration 37: 0.151043645022
Loss at the end of iteration 38: 0.147934077858
Loss at the end of iteration 39: 0.144888528004
Loss at the end of iteration 40: 0.141905677523
Loss at the end of iteration 41: 0.13898423561
Loss at the end of iteration 42: 0.136122938034
Loss at the end of iteration 43: 0.13332054659
Loss at the end of iteration 44: 0.130575848566
Loss at the end of iteration 45: 0.127887656216
Loss at the end of iteration 46: 0.125254806244
Loss at the end of iteration 47: 0.122676159307
Loss at the end of iteration 48: 0.120150599514
Loss at the end of iteration 49: 0.11767703395
Loss at the end of iteration 50: 0.115254392198
Loss at the end of iteration 51: 0.112881625879
Loss at the end of iteration 52: 0.110557708198
Loss at the end of iteration 53: 0.108281633497
Loss at the end of iteration 54: 0.106052416823
Loss at the end of iteration 55: 0.103869093499
Loss at the end of iteration 56: 0.10173071871
Loss at the end of iteration 57: 0.0996363670913
Loss at the end of iteration 58: 0.0975851323278
Loss at the end of iteration 59: 0.095576126764
Loss at the end of iteration 60: 0.0936084810187
Loss at the end of iteration 61: 0.0916813436086
Loss at the end of iteration 62: 0.0897938805801
Loss at the end of iteration 63: 0.0879452751484
Loss at the end of iteration 64: 0.086134727344
Loss at the end of iteration 65: 0.0843614536666
Loss at the end of iteration 66: 0.0826246867459
Loss at the end of iteration 67: 0.0809236750096
Loss at the end of iteration 68: 0.0792576823583
Loss at the end of iteration 69: 0.0776259878468
Loss at the end of iteration 70: 0.076027885372
Loss at the end of iteration 71: 0.0744626833677
Loss at the end of iteration 72: 0.0729297045049
Loss at the end of iteration 73: 0.0714282853992
Loss at the end of iteration 74: 0.0699577763231
Loss at the end of iteration 75: 0.0685175409255
Loss at the end of iteration 76: 0.0671069559558
Loss at the end of iteration 77: 0.0657254109943
Loss at the end of iteration 78: 0.0643723081884
Loss at the end of iteration 79: 0.0630470619935
Loss at the end of iteration 80: 0.0617490989196
Loss at the end of iteration 81: 0.0604778572834
Loss at the end of iteration 82: 0.0592327869651
Loss at the end of iteration 83: 0.0580133491704
Loss at the end of iteration 84: 0.0568190161969
Loss at the end of iteration 85: 0.0556492712067
Loss at the end of iteration 86: 0.0545036080016
Loss at the end of iteration 87: 0.0533815308049
Loss at the end of iteration 88: 0.0522825540466
Loss at the end of iteration 89: 0.051206202153
Loss at the end of iteration 90: 0.0501520093413
Loss at the end of iteration 91: 0.049119519418
Loss at the end of iteration 92: 0.048108285581
Loss at the end of iteration 93: 0.0471178702268
Loss at the end of iteration 94: 0.046147844761
Loss at the end of iteration 95: 0.0451977894128
Loss at the end of iteration 96: 0.044267293053
Loss at the end of iteration 97: 0.0433559530167
Loss at the end of iteration 98: 0.0424633749287
Loss at the end of iteration 99: 0.0415891725328
CROSS VALIDATION 10
Loss at the end of iteration 0: 36.3887491026
Loss at the end of iteration 1: 0.305680026437
Loss at the end of iteration 2: 0.299386927692
Loss at the end of iteration 3: 0.293223386289
Loss at the end of iteration 4: 0.287186735003
Loss at the end of iteration 5: 0.281274361523
Loss at the end of iteration 6: 0.275483707314
Loss at the end of iteration 7: 0.269812266517
Loss at the end of iteration 8: 0.264257584859
Loss at the end of iteration 9: 0.258817258597
Loss at the end of iteration 10: 0.25348893347
Loss at the end of iteration 11: 0.24827030369
Loss at the end of iteration 12: 0.243159110934
Loss at the end of iteration 13: 0.238153143375
Loss at the end of iteration 14: 0.233250234718
Loss at the end of iteration 15: 0.228448263269
Loss at the end of iteration 16: 0.223745151012
Loss at the end of iteration 17: 0.219138862712
Loss at the end of iteration 18: 0.214627405035
Loss at the end of iteration 19: 0.210208825682
Loss at the end of iteration 20: 0.205881212548
Loss at the end of iteration 21: 0.201642692893
Loss at the end of iteration 22: 0.197491432529
Loss at the end of iteration 23: 0.193425635032
Loss at the end of iteration 24: 0.18944354096
Loss at the end of iteration 25: 0.185543427093
Loss at the end of iteration 26: 0.181723605688
Loss at the end of iteration 27: 0.177982423746
Loss at the end of iteration 28: 0.1743182623
Loss at the end of iteration 29: 0.170729535713
Loss at the end of iteration 30: 0.167214690993
Loss at the end of iteration 31: 0.163772207117
Loss at the end of iteration 32: 0.160400594378
Loss at the end of iteration 33: 0.157098393737
Loss at the end of iteration 34: 0.153864176193
Loss at the end of iteration 35: 0.150696542162
Loss at the end of iteration 36: 0.147594120877
Loss at the end of iteration 37: 0.144555569789
Loss at the end of iteration 38: 0.141579573989
Loss at the end of iteration 39: 0.138664845638
Loss at the end of iteration 40: 0.13581012341
Loss at the end of iteration 41: 0.133014171946
Loss at the end of iteration 42: 0.130275781321
Loss at the end of iteration 43: 0.127593766518
Loss at the end of iteration 44: 0.124966966915
Loss at the end of iteration 45: 0.122394245786
Loss at the end of iteration 46: 0.119874489806
Loss at the end of iteration 47: 0.11740660857
Loss at the end of iteration 48: 0.114989534122
Loss at the end of iteration 49: 0.112622220492
Loss at the end of iteration 50: 0.110303643244
Loss at the end of iteration 51: 0.108032799032
Loss at the end of iteration 52: 0.105808705165
Loss at the end of iteration 53: 0.103630399184
Loss at the end of iteration 54: 0.101496938445
Loss at the end of iteration 55: 0.0994073997093
Loss at the end of iteration 56: 0.0973608787452
Loss at the end of iteration 57: 0.095356489937
Loss at the end of iteration 58: 0.093393365901
Loss at the end of iteration 59: 0.0914706571109
Loss at the end of iteration 60: 0.0895875315295
Loss at the end of iteration 61: 0.0877431742489
Loss at the end of iteration 62: 0.0859367871381
Loss at the end of iteration 63: 0.0841675884971
Loss at the end of iteration 64: 0.0824348127193
Loss at the end of iteration 65: 0.0807377099594
Loss at the end of iteration 66: 0.0790755458095
Loss at the end of iteration 67: 0.0774476009813
Loss at the end of iteration 68: 0.0758531709943
Loss at the end of iteration 69: 0.0742915658714
Loss at the end of iteration 70: 0.0727621098404
Loss at the end of iteration 71: 0.0712641410412
Loss at the end of iteration 72: 0.0697970112394
Loss at the end of iteration 73: 0.0683600855463
Loss at the end of iteration 74: 0.0669527421434
Loss at the end of iteration 75: 0.065574372014
Loss at the end of iteration 76: 0.0642243786792
Loss at the end of iteration 77: 0.0629021779401
Loss at the end of iteration 78: 0.0616071976245
Loss at the end of iteration 79: 0.0603388773401
Loss at the end of iteration 80: 0.059096668231
Loss at the end of iteration 81: 0.0578800327411
Loss at the end of iteration 82: 0.056688444381
Loss at the end of iteration 83: 0.0555213875
Loss at the end of iteration 84: 0.0543783570636
Loss at the end of iteration 85: 0.0532588584342
Loss at the end of iteration 86: 0.0521624071577
Loss at the end of iteration 87: 0.0510885287533
Loss at the end of iteration 88: 0.0500367585086
Loss at the end of iteration 89: 0.0490066412782
Loss at the end of iteration 90: 0.0479977312871
Loss at the end of iteration 91: 0.0470095919374
Loss at the end of iteration 92: 0.0460417956195
Loss at the end of iteration 93: 0.0450939235271
Loss at the end of iteration 94: 0.0441655654761
Loss at the end of iteration 95: 0.0432563197267
Loss at the end of iteration 96: 0.0423657928101
Loss at the end of iteration 97: 0.0414935993577
Loss at the end of iteration 98: 0.0406393619347
Loss at the end of iteration 99: 0.0483378000196
CROSS VALIDATION 11
Loss at the end of iteration 0: 36.3887491026
Loss at the end of iteration 1: 0.288454291847
Loss at the end of iteration 2: 0.282515822908
Loss at the end of iteration 3: 0.276699610474
Loss at the end of iteration 4: 0.271003137623
Loss at the end of iteration 5: 0.265423939253
Loss at the end of iteration 6: 0.259959601008
Loss at the end of iteration 7: 0.254607758239
Loss at the end of iteration 8: 0.249366094979
Loss at the end of iteration 9: 0.244232342938
Loss at the end of iteration 10: 0.239204280526
Loss at the end of iteration 11: 0.234279731889
Loss at the end of iteration 12: 0.229456565966
Loss at the end of iteration 13: 0.22473269557
Loss at the end of iteration 14: 0.220106076484
Loss at the end of iteration 15: 0.215574706574
Loss at the end of iteration 16: 0.211136624926
Loss at the end of iteration 17: 0.206789910995
Loss at the end of iteration 18: 0.202532683774
Loss at the end of iteration 19: 0.198363100981
Loss at the end of iteration 20: 0.194279358264
Loss at the end of iteration 21: 0.190279688413
Loss at the end of iteration 22: 0.186362360603
Loss at the end of iteration 23: 0.182525679641
Loss at the end of iteration 24: 0.178767985235
Loss at the end of iteration 25: 0.17508765127
Loss at the end of iteration 26: 0.171483085112
Loss at the end of iteration 27: 0.167952726912
Loss at the end of iteration 28: 0.164495048936
Loss at the end of iteration 29: 0.161108554901
Loss at the end of iteration 30: 0.157791779329
Loss at the end of iteration 31: 0.15454328691
Loss at the end of iteration 32: 0.151361671885
Loss at the end of iteration 33: 0.148245557435
Loss at the end of iteration 34: 0.145193595086
Loss at the end of iteration 35: 0.142204464125
Loss at the end of iteration 36: 0.139276871029
Loss at the end of iteration 37: 0.136409548906
Loss at the end of iteration 38: 0.133601256945
Loss at the end of iteration 39: 0.130850779878
Loss at the end of iteration 40: 0.128156927459
Loss at the end of iteration 41: 0.125518533944
Loss at the end of iteration 42: 0.122934457589
Loss at the end of iteration 43: 0.120403580155
Loss at the end of iteration 44: 0.117924806425
Loss at the end of iteration 45: 0.11549706373
Loss at the end of iteration 46: 0.113119301482
Loss at the end of iteration 47: 0.110790490723
Loss at the end of iteration 48: 0.108509623679
Loss at the end of iteration 49: 0.106275713324
Loss at the end of iteration 50: 0.104087792948
Loss at the end of iteration 51: 0.101944915748
Loss at the end of iteration 52: 0.0998461544094
Loss at the end of iteration 53: 0.0977906007104
Loss at the end of iteration 54: 0.095777365126
Loss at the end of iteration 55: 0.0938055764444
Loss at the end of iteration 56: 0.0918743813895
Loss at the end of iteration 57: 0.0899829442517
Loss at the end of iteration 58: 0.0881304465266
Loss at the end of iteration 59: 0.0863160865602
Loss at the end of iteration 60: 0.0845390792026
Loss at the end of iteration 61: 0.0827986554678
Loss at the end of iteration 62: 0.081094062201
Loss at the end of iteration 63: 0.0794245617529
Loss at the end of iteration 64: 0.0777894316603
Loss at the end of iteration 65: 0.0761879643335
Loss at the end of iteration 66: 0.07461946675
Loss at the end of iteration 67: 0.073083260155
Loss at the end of iteration 68: 0.0715786797669
Loss at the end of iteration 69: 0.0701050744905
Loss at the end of iteration 70: 0.0686618066346
Loss at the end of iteration 71: 0.0672482516365
Loss at the end of iteration 72: 0.0658637977913
Loss at the end of iteration 73: 0.0645078459874
Loss at the end of iteration 74: 0.0631798094474
Loss at the end of iteration 75: 0.0618791134738
Loss at the end of iteration 76: 0.0606051952008
Loss at the end of iteration 77: 0.0593575033502
Loss at the end of iteration 78: 0.058135497993
Loss at the end of iteration 79: 0.0569386503162
Loss at the end of iteration 80: 0.0557664423933
Loss at the end of iteration 81: 0.0546183669604
Loss at the end of iteration 82: 0.053493927197
Loss at the end of iteration 83: 0.0523926365106
Loss at the end of iteration 84: 0.0513140183263
Loss at the end of iteration 85: 0.0502576058805
Loss at the end of iteration 86: 0.049222942019
Loss at the end of iteration 87: 0.0482095789993
Loss at the end of iteration 88: 0.0472170782963
Loss at the end of iteration 89: 0.0462450104132
Loss at the end of iteration 90: 0.0452929546953
Loss at the end of iteration 91: 0.0443604991479
Loss at the end of iteration 92: 0.0434472402582
Loss at the end of iteration 93: 0.0425527828207
Loss at the end of iteration 94: 0.0416767397657
Loss at the end of iteration 95: 0.0408187319927
Loss at the end of iteration 96: 0.0399783882055
Loss at the end of iteration 97: 0.0391553447519
Loss at the end of iteration 98: 0.0383492454662
Loss at the end of iteration 99: 0.0375597415155
CROSS VALIDATION 12
Loss at the end of iteration 0: 36.3887491026
Loss at the end of iteration 1: 0.305686898999
Loss at the end of iteration 2: 0.299393658767
Loss at the end of iteration 3: 0.29322997879
Loss at the end of iteration 4: 0.287193191783
Loss at the end of iteration 5: 0.281280685376
Loss at the end of iteration 6: 0.275489900976
Loss at the end of iteration 7: 0.269818332669
Loss at the end of iteration 8: 0.264263526126
Loss at the end of iteration 9: 0.258823077549
Loss at the end of iteration 10: 0.253494632627
Loss at the end of iteration 11: 0.248275885517
Loss at the end of iteration 12: 0.243164577847
Loss at the end of iteration 13: 0.238158497739
Loss at the end of iteration 14: 0.233255478851
Loss at the end of iteration 15: 0.22845339944
Loss at the end of iteration 16: 0.223750181443
Loss at the end of iteration 17: 0.219143789581
Loss at the end of iteration 18: 0.214632230474
Loss at the end of iteration 19: 0.210213551778
Loss at the end of iteration 20: 0.205885841347
Loss at the end of iteration 21: 0.201647226398
Loss at the end of iteration 22: 0.197495872702
Loss at the end of iteration 23: 0.193429983794
Loss at the end of iteration 24: 0.189447800193
Loss at the end of iteration 25: 0.185547598641
Loss at the end of iteration 26: 0.181727691354
Loss at the end of iteration 27: 0.1779864253
Loss at the end of iteration 28: 0.174322181473
Loss at the end of iteration 29: 0.170733374202
Loss at the end of iteration 30: 0.167218450458
Loss at the end of iteration 31: 0.163775889185
Loss at the end of iteration 32: 0.160404200643
Loss at the end of iteration 33: 0.157101925759
Loss at the end of iteration 34: 0.1538676355
Loss at the end of iteration 35: 0.150699930252
Loss at the end of iteration 36: 0.147597439215
Loss at the end of iteration 37: 0.144558819812
Loss at the end of iteration 38: 0.141582757103
Loss at the end of iteration 39: 0.13866796322
Loss at the end of iteration 40: 0.13581317681
Loss at the end of iteration 41: 0.133017162485
Loss at the end of iteration 42: 0.130278710294
Loss at the end of iteration 43: 0.127596635191
Loss at the end of iteration 44: 0.12496977653
Loss at the end of iteration 45: 0.122396997559
Loss at the end of iteration 46: 0.119877184928
Loss at the end of iteration 47: 0.117409248207
Loss at the end of iteration 48: 0.114992119416
Loss at the end of iteration 49: 0.112624752562
Loss at the end of iteration 50: 0.110306123186
Loss at the end of iteration 51: 0.108035227918
Loss at the end of iteration 52: 0.105811084047
Loss at the end of iteration 53: 0.103632729092
Loss at the end of iteration 54: 0.101499220387
Loss at the end of iteration 55: 0.0994096346722
Loss at the end of iteration 56: 0.0973630676964
Loss at the end of iteration 57: 0.0953586338238
Loss at the end of iteration 58: 0.0933954656512
Loss at the end of iteration 59: 0.0914727136331
Loss at the end of iteration 60: 0.0895895457136
Loss at the end of iteration 61: 0.0877451469666
Loss at the end of iteration 62: 0.085938719243
Loss at the end of iteration 63: 0.0841694808254
Loss at the end of iteration 64: 0.0824366660898
Loss at the end of iteration 65: 0.0807395251742
Loss at the end of iteration 66: 0.0790773236541
Loss at the end of iteration 67: 0.077449342225
Loss at the end of iteration 68: 0.0758548763907
Loss at the end of iteration 69: 0.0742932361585
Loss at the end of iteration 70: 0.0727637457409
Loss at the end of iteration 71: 0.071265743263
Loss at the end of iteration 72: 0.069798580476
Loss at the end of iteration 73: 0.0683616224766
Loss at the end of iteration 74: 0.0669542474327
Loss at the end of iteration 75: 0.0655758463136
Loss at the end of iteration 76: 0.0642258226271
Loss at the end of iteration 77: 0.0629035921611
Loss at the end of iteration 78: 0.0616085827307
Loss at the end of iteration 79: 0.0603402339307
Loss at the end of iteration 80: 0.0590979968933
Loss at the end of iteration 81: 0.0578813340499
Loss at the end of iteration 82: 0.0566897188995
Loss at the end of iteration 83: 0.0555226357797
Loss at the end of iteration 84: 0.0543795796447
Loss at the end of iteration 85: 0.0532600558458
Loss at the end of iteration 86: 0.0521635799179
Loss at the end of iteration 87: 0.0510896773696
Loss at the end of iteration 88: 0.0500378834781
Loss at the end of iteration 89: 0.0490077430878
Loss at the end of iteration 90: 0.0479988104135
Loss at the end of iteration 91: 0.0470106488476
Loss at the end of iteration 92: 0.0460428307708
Loss at the end of iteration 93: 0.0450949373676
Loss at the end of iteration 94: 0.0441665584444
Loss at the end of iteration 95: 0.0432572922526
Loss at the end of iteration 96: 0.0423667453144
Loss at the end of iteration 97: 0.0414945322526
Loss at the end of iteration 98: 0.0406402756238
Loss at the end of iteration 99: 0.0487484177127
CROSS VALIDATION 13
Loss at the end of iteration 0: 69.7040038475
Loss at the end of iteration 1: 4.59886961702
Loss at the end of iteration 2: 0.305205617472
Loss at the end of iteration 3: 0.298922285483
Loss at the end of iteration 4: 0.292768309766
Loss at the end of iteration 5: 0.286741027237
Loss at the end of iteration 6: 0.280837829636
Loss at the end of iteration 7: 0.2750561624
Loss at the end of iteration 8: 0.269393523559
Loss at the end of iteration 9: 0.263847462651
Loss at the end of iteration 10: 0.25841557966
Loss at the end of iteration 11: 0.253095523982
Loss at the end of iteration 12: 0.247884993406
Loss at the end of iteration 13: 0.242781733113
Loss at the end of iteration 14: 0.23778353471
Loss at the end of iteration 15: 0.232888235264
Loss at the end of iteration 16: 0.228093716374
Loss at the end of iteration 17: 0.223397903248
Loss at the end of iteration 18: 0.218798763811
Loss at the end of iteration 19: 0.214294307821
Loss at the end of iteration 20: 0.209882586011
Loss at the end of iteration 21: 0.205561689241
Loss at the end of iteration 22: 0.201329747679
Loss at the end of iteration 23: 0.197184929984
Loss at the end of iteration 24: 0.193125442519
Loss at the end of iteration 25: 0.189149528573
Loss at the end of iteration 26: 0.185255467601
Loss at the end of iteration 27: 0.181441574478
Loss at the end of iteration 28: 0.177706198771
Loss at the end of iteration 29: 0.174047724027
Loss at the end of iteration 30: 0.170464567068
Loss at the end of iteration 31: 0.166955177313
Loss at the end of iteration 32: 0.1635180361
Loss at the end of iteration 33: 0.160151656033
Loss at the end of iteration 34: 0.156854580338
Loss at the end of iteration 35: 0.153625382231
Loss at the end of iteration 36: 0.150462664301
Loss at the end of iteration 37: 0.147365057909
Loss at the end of iteration 38: 0.144331222588
Loss at the end of iteration 39: 0.141359845471
Loss at the end of iteration 40: 0.138449640716
Loss at the end of iteration 41: 0.135599348957
Loss at the end of iteration 42: 0.132807736752
Loss at the end of iteration 43: 0.130073596051
Loss at the end of iteration 44: 0.127395743678
Loss at the end of iteration 45: 0.124773020813
Loss at the end of iteration 46: 0.122204292493
Loss at the end of iteration 47: 0.119688447121
Loss at the end of iteration 48: 0.117224395985
Loss at the end of iteration 49: 0.114811072786
Loss at the end of iteration 50: 0.112447433177
Loss at the end of iteration 51: 0.110132454312
Loss at the end of iteration 52: 0.107865134402
Loss at the end of iteration 53: 0.105644492282
Loss at the end of iteration 54: 0.103469566986
Loss at the end of iteration 55: 0.101339417334
Loss at the end of iteration 56: 0.0992531215178
Loss at the end of iteration 57: 0.0972097767112
Loss at the end of iteration 58: 0.0952084986721
Loss at the end of iteration 59: 0.0932484213634
Loss at the end of iteration 60: 0.0913286965768
Loss at the end of iteration 61: 0.0894484935666
Loss at the end of iteration 62: 0.0876069986897
Loss at the end of iteration 63: 0.0858034150537
Loss at the end of iteration 64: 0.0840369621718
Loss at the end of iteration 65: 0.0823068756254
Loss at the end of iteration 66: 0.0806124067333
Loss at the end of iteration 67: 0.0789528222272
Loss at the end of iteration 68: 0.0773274039351
Loss at the end of iteration 69: 0.0757354484698
Loss at the end of iteration 70: 0.0741762669253
Loss at the end of iteration 71: 0.0726491845778
Loss at the end of iteration 72: 0.0711535405946
Loss at the end of iteration 73: 0.0696886877474
Loss at the end of iteration 74: 0.0682539921327
Loss at the end of iteration 75: 0.0668488328971
Loss at the end of iteration 76: 0.0654726019692
Loss at the end of iteration 77: 0.0641247037956
Loss at the end of iteration 78: 0.0628045550842
Loss at the end of iteration 79: 0.0615115845509
Loss at the end of iteration 80: 0.0602452326728
Loss at the end of iteration 81: 0.0590049514461
Loss at the end of iteration 82: 0.0577902041489
Loss at the end of iteration 83: 0.0566004651088
Loss at the end of iteration 84: 0.0554352194755
Loss at the end of iteration 85: 0.0542939629983
Loss at the end of iteration 86: 0.0531762018072
Loss at the end of iteration 87: 0.0520814522
Loss at the end of iteration 88: 0.0510092404322
Loss at the end of iteration 89: 0.0499591025128
Loss at the end of iteration 90: 0.0489305840027
Loss at the end of iteration 91: 0.0479232398187
Loss at the end of iteration 92: 0.572812578327
Loss at the end of iteration 93: 0.126323726024
Loss at the end of iteration 94: 0.123723073011
Loss at the end of iteration 95: 0.121175960187
Loss at the end of iteration 96: 0.118681285307
Loss at the end of iteration 97: 0.116237968822
Loss at the end of iteration 98: 0.113844953406
Loss at the end of iteration 99: 0.111501203499
CROSS VALIDATION 14
Loss at the end of iteration 0: 36.3824242617
Loss at the end of iteration 1: 0.305692661827
Loss at the end of iteration 2: 0.299399302954
Loss at the end of iteration 3: 0.293235506778
Loss at the end of iteration 4: 0.287198605966
Loss at the end of iteration 5: 0.281285988096
Loss at the end of iteration 6: 0.275495094528
Loss at the end of iteration 7: 0.2698234193
Loss at the end of iteration 8: 0.264268508037
Loss at the end of iteration 9: 0.258827956897
Loss at the end of iteration 10: 0.253499411523
Loss at the end of iteration 11: 0.248280566029
Loss at the end of iteration 12: 0.243169162
Loss at the end of iteration 13: 0.238162987517
Loss at the end of iteration 14: 0.233259876197
Loss at the end of iteration 15: 0.228457706256
Loss at the end of iteration 16: 0.223754399595
Loss at the end of iteration 17: 0.219147920893
Loss at the end of iteration 18: 0.214636276733
Loss at the end of iteration 19: 0.210217514737
Loss at the end of iteration 20: 0.205889722719
Loss at the end of iteration 21: 0.201651027863
Loss at the end of iteration 22: 0.197499595906
Loss at the end of iteration 23: 0.193433630348
Loss at the end of iteration 24: 0.189451371674
Loss at the end of iteration 25: 0.185551096595
Loss at the end of iteration 26: 0.181731117296
Loss at the end of iteration 27: 0.17798978071
Loss at the end of iteration 28: 0.174325467805
Loss at the end of iteration 29: 0.170736592878
Loss at the end of iteration 30: 0.16722160287
Loss at the end of iteration 31: 0.163778976698
Loss at the end of iteration 32: 0.160407224592
Loss at the end of iteration 33: 0.157104887454
Loss at the end of iteration 34: 0.153870536221
Loss at the end of iteration 35: 0.150702771256
Loss at the end of iteration 36: 0.147600221731
Loss at the end of iteration 37: 0.144561545043
Loss at the end of iteration 38: 0.141585426229
Loss at the end of iteration 39: 0.138670577397
Loss at the end of iteration 40: 0.135815737168
Loss at the end of iteration 41: 0.133019670133
Loss at the end of iteration 42: 0.130281166316
Loss at the end of iteration 43: 0.12759904065
Loss at the end of iteration 44: 0.124972132468
Loss at the end of iteration 45: 0.122399304994
Loss at the end of iteration 46: 0.119879444859
Loss at the end of iteration 47: 0.117411461613
Loss at the end of iteration 48: 0.114994287254
Loss at the end of iteration 49: 0.112626875771
Loss at the end of iteration 50: 0.110308202683
Loss at the end of iteration 51: 0.108037264605
Loss at the end of iteration 52: 0.105813078804
Loss at the end of iteration 53: 0.103634682782
Loss at the end of iteration 54: 0.101501133856
Loss at the end of iteration 55: 0.0994115087484
Loss at the end of iteration 56: 0.0973649031907
Loss at the end of iteration 57: 0.0953604315303
Loss at the end of iteration 58: 0.093397226348
Loss at the end of iteration 59: 0.0914744380821
Loss at the end of iteration 60: 0.089591234661
Loss at the end of iteration 61: 0.0877468011432
Loss at the end of iteration 62: 0.0859403393648
Loss at the end of iteration 63: 0.0841710675934
Loss at the end of iteration 64: 0.0824382201907
Loss at the end of iteration 65: 0.0807410472804
Loss at the end of iteration 66: 0.0790788144245
Loss at the end of iteration 67: 0.0774508023046
Loss at the end of iteration 68: 0.0758563064112
Loss at the end of iteration 69: 0.0742946367389
Loss at the end of iteration 70: 0.0727651174873
Loss at the end of iteration 71: 0.071267086769
Loss at the end of iteration 72: 0.0697998963229
Loss at the end of iteration 73: 0.068362911234
Loss at the end of iteration 74: 0.0669555096581
Loss at the end of iteration 75: 0.0655770825533
Loss at the end of iteration 76: 0.064227033416
Loss at the end of iteration 77: 0.0629047780233
Loss at the end of iteration 78: 0.0616097441793
Loss at the end of iteration 79: 0.0603413714684
Loss at the end of iteration 80: 0.0590991110122
Loss at the end of iteration 81: 0.0578824252322
Loss at the end of iteration 82: 0.0566907876174
Loss at the end of iteration 83: 0.0555236824957
Loss at the end of iteration 84: 0.0543806048117
Loss at the end of iteration 85: 0.0532610599075
Loss at the end of iteration 86: 0.0521645633087
Loss at the end of iteration 87: 0.0510906405152
Loss at the end of iteration 88: 0.0500388267952
Loss at the end of iteration 89: 0.0490086669846
Loss at the end of iteration 90: 0.0479997152899
Loss at the end of iteration 91: 0.0470115350951
Loss at the end of iteration 92: 0.0460436987729
Loss at the end of iteration 93: 0.0450957875
Loss at the end of iteration 94: 0.0441673910749
Loss at the end of iteration 95: 0.0432581077416
Loss at the end of iteration 96: 0.0423675440148
Loss at the end of iteration 97: 0.04149531451
Loss at the end of iteration 98: 0.0406410417767
Loss at the end of iteration 99: 0.0482615284931
CROSS VALIDATION 15
Loss at the end of iteration 0: 36.3824242617
Loss at the end of iteration 1: 0.305692661827
Loss at the end of iteration 2: 0.299399302954
Loss at the end of iteration 3: 0.293235506778
Loss at the end of iteration 4: 0.287198605966
Loss at the end of iteration 5: 0.281285988096
Loss at the end of iteration 6: 0.275495094528
Loss at the end of iteration 7: 0.2698234193
Loss at the end of iteration 8: 0.264268508037
Loss at the end of iteration 9: 0.258827956897
Loss at the end of iteration 10: 0.253499411523
Loss at the end of iteration 11: 0.248280566029
Loss at the end of iteration 12: 0.243169162
Loss at the end of iteration 13: 0.238162987517
Loss at the end of iteration 14: 0.233259876197
Loss at the end of iteration 15: 0.228457706256
Loss at the end of iteration 16: 0.223754399595
Loss at the end of iteration 17: 0.219147920893
Loss at the end of iteration 18: 0.214636276733
Loss at the end of iteration 19: 0.210217514737
Loss at the end of iteration 20: 0.205889722719
Loss at the end of iteration 21: 0.201651027863
Loss at the end of iteration 22: 0.197499595906
Loss at the end of iteration 23: 0.193433630348
Loss at the end of iteration 24: 0.189451371674
Loss at the end of iteration 25: 0.185551096595
Loss at the end of iteration 26: 0.181731117296
Loss at the end of iteration 27: 0.17798978071
Loss at the end of iteration 28: 0.174325467805
Loss at the end of iteration 29: 0.170736592878
Loss at the end of iteration 30: 0.16722160287
Loss at the end of iteration 31: 0.163778976698
Loss at the end of iteration 32: 0.160407224592
Loss at the end of iteration 33: 0.157104887454
Loss at the end of iteration 34: 0.153870536221
Loss at the end of iteration 35: 0.150702771256
Loss at the end of iteration 36: 0.147600221731
Loss at the end of iteration 37: 0.144561545043
Loss at the end of iteration 38: 0.141585426229
Loss at the end of iteration 39: 0.138670577397
Loss at the end of iteration 40: 0.135815737168
Loss at the end of iteration 41: 0.133019670133
Loss at the end of iteration 42: 0.130281166316
Loss at the end of iteration 43: 0.12759904065
Loss at the end of iteration 44: 0.124972132468
Loss at the end of iteration 45: 0.122399304994
Loss at the end of iteration 46: 0.119879444859
Loss at the end of iteration 47: 0.117411461613
Loss at the end of iteration 48: 0.114994287254
Loss at the end of iteration 49: 0.112626875771
Loss at the end of iteration 50: 0.110308202683
Loss at the end of iteration 51: 0.108037264605
Loss at the end of iteration 52: 0.105813078804
Loss at the end of iteration 53: 0.103634682782
Loss at the end of iteration 54: 0.101501133856
Loss at the end of iteration 55: 0.0994115087484
Loss at the end of iteration 56: 0.0973649031907
Loss at the end of iteration 57: 0.0953604315303
Loss at the end of iteration 58: 0.093397226348
Loss at the end of iteration 59: 0.0914744380821
Loss at the end of iteration 60: 0.089591234661
Loss at the end of iteration 61: 0.0877468011432
Loss at the end of iteration 62: 0.0859403393648
Loss at the end of iteration 63: 0.0841710675934
Loss at the end of iteration 64: 0.0824382201907
Loss at the end of iteration 65: 0.0807410472804
Loss at the end of iteration 66: 0.0790788144245
Loss at the end of iteration 67: 0.0774508023046
Loss at the end of iteration 68: 0.0758563064112
Loss at the end of iteration 69: 0.0742946367389
Loss at the end of iteration 70: 0.0727651174873
Loss at the end of iteration 71: 0.071267086769
Loss at the end of iteration 72: 0.0697998963229
Loss at the end of iteration 73: 0.068362911234
Loss at the end of iteration 74: 0.0669555096581
Loss at the end of iteration 75: 0.0655770825533
Loss at the end of iteration 76: 0.064227033416
Loss at the end of iteration 77: 0.0629047780233
Loss at the end of iteration 78: 0.0616097441793
Loss at the end of iteration 79: 0.0603413714684
Loss at the end of iteration 80: 0.0590991110122
Loss at the end of iteration 81: 0.0578824252322
Loss at the end of iteration 82: 0.0566907876174
Loss at the end of iteration 83: 0.0555236824957
Loss at the end of iteration 84: 0.0543806048117
Loss at the end of iteration 85: 0.0532610599075
Loss at the end of iteration 86: 0.0521645633087
Loss at the end of iteration 87: 0.0510906405152
Loss at the end of iteration 88: 0.0500388267952
Loss at the end of iteration 89: 0.0490086669846
Loss at the end of iteration 90: 0.0479997152899
Loss at the end of iteration 91: 0.0470115350951
Loss at the end of iteration 92: 0.0460436987729
Loss at the end of iteration 93: 0.0450957875
Loss at the end of iteration 94: 0.0441673910749
Loss at the end of iteration 95: 0.0432581077416
Loss at the end of iteration 96: 0.0423675440148
Loss at the end of iteration 97: 0.04149531451
Loss at the end of iteration 98: 0.0406410417767
Loss at the end of iteration 99: 0.0482615284931
CROSS VALIDATION 16
Loss at the end of iteration 0: 36.3824242617
Loss at the end of iteration 1: 0.305692661827
Loss at the end of iteration 2: 0.299399302954
Loss at the end of iteration 3: 0.293235506778
Loss at the end of iteration 4: 0.287198605966
Loss at the end of iteration 5: 0.281285988096
Loss at the end of iteration 6: 0.275495094528
Loss at the end of iteration 7: 0.2698234193
Loss at the end of iteration 8: 0.264268508037
Loss at the end of iteration 9: 0.258827956897
Loss at the end of iteration 10: 0.253499411523
Loss at the end of iteration 11: 0.248280566029
Loss at the end of iteration 12: 0.243169162
Loss at the end of iteration 13: 0.238162987517
Loss at the end of iteration 14: 0.233259876197
Loss at the end of iteration 15: 0.228457706256
Loss at the end of iteration 16: 0.223754399595
Loss at the end of iteration 17: 0.219147920893
Loss at the end of iteration 18: 0.214636276733
Loss at the end of iteration 19: 0.210217514737
Loss at the end of iteration 20: 0.205889722719
Loss at the end of iteration 21: 0.201651027863
Loss at the end of iteration 22: 0.197499595906
Loss at the end of iteration 23: 0.193433630348
Loss at the end of iteration 24: 0.189451371674
Loss at the end of iteration 25: 0.185551096595
Loss at the end of iteration 26: 0.181731117296
Loss at the end of iteration 27: 0.17798978071
Loss at the end of iteration 28: 0.174325467805
Loss at the end of iteration 29: 0.170736592878
Loss at the end of iteration 30: 0.16722160287
Loss at the end of iteration 31: 0.163778976698
Loss at the end of iteration 32: 0.160407224592
Loss at the end of iteration 33: 0.157104887454
Loss at the end of iteration 34: 0.153870536221
Loss at the end of iteration 35: 0.150702771256
Loss at the end of iteration 36: 0.147600221731
Loss at the end of iteration 37: 0.144561545043
Loss at the end of iteration 38: 0.141585426229
Loss at the end of iteration 39: 0.138670577397
Loss at the end of iteration 40: 0.135815737168
Loss at the end of iteration 41: 0.133019670133
Loss at the end of iteration 42: 0.130281166316
Loss at the end of iteration 43: 0.12759904065
Loss at the end of iteration 44: 0.124972132468
Loss at the end of iteration 45: 0.122399304994
Loss at the end of iteration 46: 0.119879444859
Loss at the end of iteration 47: 0.117411461613
Loss at the end of iteration 48: 0.114994287254
Loss at the end of iteration 49: 0.112626875771
Loss at the end of iteration 50: 0.110308202683
Loss at the end of iteration 51: 0.108037264605
Loss at the end of iteration 52: 0.105813078804
Loss at the end of iteration 53: 0.103634682782
Loss at the end of iteration 54: 0.101501133856
Loss at the end of iteration 55: 0.0994115087484
Loss at the end of iteration 56: 0.0973649031907
Loss at the end of iteration 57: 0.0953604315303
Loss at the end of iteration 58: 0.093397226348
Loss at the end of iteration 59: 0.0914744380821
Loss at the end of iteration 60: 0.089591234661
Loss at the end of iteration 61: 0.0877468011432
Loss at the end of iteration 62: 0.0859403393648
Loss at the end of iteration 63: 0.0841710675934
Loss at the end of iteration 64: 0.0824382201907
Loss at the end of iteration 65: 0.0807410472804
Loss at the end of iteration 66: 0.0790788144245
Loss at the end of iteration 67: 0.0774508023046
Loss at the end of iteration 68: 0.0758563064112
Loss at the end of iteration 69: 0.0742946367389
Loss at the end of iteration 70: 0.0727651174873
Loss at the end of iteration 71: 0.071267086769
Loss at the end of iteration 72: 0.0697998963229
Loss at the end of iteration 73: 0.068362911234
Loss at the end of iteration 74: 0.0669555096581
Loss at the end of iteration 75: 0.0655770825533
Loss at the end of iteration 76: 0.064227033416
Loss at the end of iteration 77: 0.0629047780233
Loss at the end of iteration 78: 0.0616097441793
Loss at the end of iteration 79: 0.0603413714684
Loss at the end of iteration 80: 0.0590991110122
Loss at the end of iteration 81: 0.0578824252322
Loss at the end of iteration 82: 0.0566907876174
Loss at the end of iteration 83: 0.0555236824957
Loss at the end of iteration 84: 0.0543806048117
Loss at the end of iteration 85: 0.0532610599075
Loss at the end of iteration 86: 0.0521645633087
Loss at the end of iteration 87: 0.0510906405152
Loss at the end of iteration 88: 0.0500388267952
Loss at the end of iteration 89: 0.0490086669846
Loss at the end of iteration 90: 0.0479997152899
Loss at the end of iteration 91: 0.0470115350951
Loss at the end of iteration 92: 0.0460436987729
Loss at the end of iteration 93: 0.0450957875
Loss at the end of iteration 94: 0.0441673910749
Loss at the end of iteration 95: 0.0432581077416
Loss at the end of iteration 96: 0.0423675440148
Loss at the end of iteration 97: 0.04149531451
Loss at the end of iteration 98: 0.0406410417767
Loss at the end of iteration 99: 0.0482615284931
CROSS VALIDATION 17
Loss at the end of iteration 0: 26.5411282387
Loss at the end of iteration 1: 2.85650743872
Loss at the end of iteration 2: 0.318996564845
Loss at the end of iteration 3: 0.312429315733
Loss at the end of iteration 4: 0.305997267955
Loss at the end of iteration 5: 0.299697638092
Loss at the end of iteration 6: 0.293527700029
Loss at the end of iteration 7: 0.287484783773
Loss at the end of iteration 8: 0.2815662743
Loss at the end of iteration 9: 0.275769610422
Loss at the end of iteration 10: 0.270092283677
Loss at the end of iteration 11: 0.264531837247
Loss at the end of iteration 12: 0.259085864893
Loss at the end of iteration 13: 0.253752009913
Loss at the end of iteration 14: 0.248527964123
Loss at the end of iteration 15: 0.243411466858
Loss at the end of iteration 16: 0.238400303994
Loss at the end of iteration 17: 0.23349230699
Loss at the end of iteration 18: 0.228685351948
Loss at the end of iteration 19: 0.223977358697
Loss at the end of iteration 20: 0.219366289889
Loss at the end of iteration 21: 0.214850150121
Loss at the end of iteration 22: 0.210426985069
Loss at the end of iteration 23: 0.206094880642
Loss at the end of iteration 24: 0.201851962156
Loss at the end of iteration 25: 0.197696393522
Loss at the end of iteration 26: 0.193626376451
Loss at the end of iteration 27: 0.189640149673
Loss at the end of iteration 28: 0.185735988181
Loss at the end of iteration 29: 0.18191220248
Loss at the end of iteration 30: 0.178167137856
Loss at the end of iteration 31: 0.174499173662
Loss at the end of iteration 32: 0.170906722616
Loss at the end of iteration 33: 0.167388230112
Loss at the end of iteration 34: 0.16394217355
Loss at the end of iteration 35: 0.160567061676
Loss at the end of iteration 36: 0.157261433938
Loss at the end of iteration 37: 0.154023859851
Loss at the end of iteration 38: 0.150852938379
Loss at the end of iteration 39: 0.147747297333
Loss at the end of iteration 40: 0.144705592769
Loss at the end of iteration 41: 0.141726508414
Loss at the end of iteration 42: 0.138808755093
Loss at the end of iteration 43: 0.135951070171
Loss at the end of iteration 44: 0.133152217007
Loss at the end of iteration 45: 0.130410984419
Loss at the end of iteration 46: 0.127726186161
Loss at the end of iteration 47: 0.125096660408
Loss at the end of iteration 48: 0.122521269252
Loss at the end of iteration 49: 0.119998898213
Loss at the end of iteration 50: 0.117528455755
Loss at the end of iteration 51: 0.115108872814
Loss at the end of iteration 52: 0.112739102333
Loss at the end of iteration 53: 0.110418118814
Loss at the end of iteration 54: 0.108144917869
Loss at the end of iteration 55: 0.105918515788
Loss at the end of iteration 56: 0.103737949113
Loss at the end of iteration 57: 0.101602274221
Loss at the end of iteration 58: 0.0995105669157
Loss at the end of iteration 59: 0.0974619220267
Loss at the end of iteration 60: 0.0954554530192
Loss at the end of iteration 61: 0.0934902916096
Loss at the end of iteration 62: 0.0915655873896
Loss at the end of iteration 63: 0.0896805074586
Loss at the end of iteration 64: 0.0878342360631
Loss at the end of iteration 65: 0.0860259742436
Loss at the end of iteration 66: 0.0842549394891
Loss at the end of iteration 67: 0.082520365398
Loss at the end of iteration 68: 0.0808215013472
Loss at the end of iteration 69: 0.0791576121665
Loss at the end of iteration 70: 0.077527977821
Loss at the end of iteration 71: 0.0759318930991
Loss at the end of iteration 72: 0.0743686673078
Loss at the end of iteration 73: 0.0728376239734
Loss at the end of iteration 74: 0.0713381005489
Loss at the end of iteration 75: 0.0698694481272
Loss at the end of iteration 76: 0.0684310311607
Loss at the end of iteration 77: 0.0670222271856
Loss at the end of iteration 78: 0.0656424265531
Loss at the end of iteration 79: 0.0642910321652
Loss at the end of iteration 80: 0.0629674592168
Loss at the end of iteration 81: 0.061671134942
Loss at the end of iteration 82: 0.0604014983665
Loss at the end of iteration 83: 0.0591580000653
Loss at the end of iteration 84: 0.0579401019241
Loss at the end of iteration 85: 0.0567472769071
Loss at the end of iteration 86: 0.0555790088286
Loss at the end of iteration 87: 0.0544347921298
Loss at the end of iteration 88: 0.0533141316599
Loss at the end of iteration 89: 0.0522165424619
Loss at the end of iteration 90: 0.0511415495626
Loss at the end of iteration 91: 0.0500886877674
Loss at the end of iteration 92: 0.0490575014585
Loss at the end of iteration 93: 0.0480475443982
Loss at the end of iteration 94: 0.0470583795355
Loss at the end of iteration 95: 0.0460895788171
Loss at the end of iteration 96: 0.045140723002
Loss at the end of iteration 97: 0.0442114014804
Loss at the end of iteration 98: 0.0433012120957
Loss at the end of iteration 99: 0.0424097609705
CROSS VALIDATION 18
Loss at the end of iteration 0: 36.3824242617
Loss at the end of iteration 1: 0.305698728599
Loss at the end of iteration 2: 0.299405244828
Loss at the end of iteration 3: 0.293241326326
Loss at the end of iteration 4: 0.287204305705
Loss at the end of iteration 5: 0.281291570493
Loss at the end of iteration 6: 0.275500562
Loss at the end of iteration 7: 0.269828774211
Loss at the end of iteration 8: 0.264273752706
Loss at the end of iteration 9: 0.258833093593
Loss at the end of iteration 10: 0.253504442468
Loss at the end of iteration 11: 0.248285493401
Loss at the end of iteration 12: 0.243173987932
Loss at the end of iteration 13: 0.238167714096
Loss at the end of iteration 14: 0.233264505469
Loss at the end of iteration 15: 0.228462240225
Loss at the end of iteration 16: 0.223758840221
Loss at the end of iteration 17: 0.219152270099
Loss at the end of iteration 18: 0.214640536401
Loss at the end of iteration 19: 0.21022168671
Loss at the end of iteration 20: 0.205893808804
Loss at the end of iteration 21: 0.201655029826
Loss at the end of iteration 22: 0.19750351548
Loss at the end of iteration 23: 0.193437469229
Loss at the end of iteration 24: 0.189455131524
Loss at the end of iteration 25: 0.185554779039
Loss at the end of iteration 26: 0.181734723929
Loss at the end of iteration 27: 0.177993313093
Loss at the end of iteration 28: 0.174328927466
Loss at the end of iteration 29: 0.170739981313
Loss at the end of iteration 30: 0.167224921547
Loss at the end of iteration 31: 0.163782227053
Loss at the end of iteration 32: 0.160410408032
Loss at the end of iteration 33: 0.157108005355
Loss at the end of iteration 34: 0.153873589934
Loss at the end of iteration 35: 0.150705762101
Loss at the end of iteration 36: 0.147603151003
Loss at the end of iteration 37: 0.14456441401
Loss at the end of iteration 38: 0.141588236132
Loss at the end of iteration 39: 0.138673329451
Loss at the end of iteration 40: 0.135818432565
Loss at the end of iteration 41: 0.133022310039
Loss at the end of iteration 42: 0.130283751874
Loss at the end of iteration 43: 0.127601572979
Loss at the end of iteration 44: 0.124974612663
Loss at the end of iteration 45: 0.122401734129
Loss at the end of iteration 46: 0.119881823985
Loss at the end of iteration 47: 0.117413791759
Loss at the end of iteration 48: 0.114996569429
Loss at the end of iteration 49: 0.112629110962
Loss at the end of iteration 50: 0.110310391858
Loss at the end of iteration 51: 0.108039408711
Loss at the end of iteration 52: 0.105815178769
Loss at the end of iteration 53: 0.103636739515
Loss at the end of iteration 54: 0.101503148246
Loss at the end of iteration 55: 0.0994134816678
Loss at the end of iteration 56: 0.0973668354931
Loss at the end of iteration 57: 0.0953623240521
Loss at the end of iteration 58: 0.093399079908
Loss at the end of iteration 59: 0.0914762534824
Loss at the end of iteration 60: 0.0895930126873
Loss at the end of iteration 61: 0.087748542565
Loss at the end of iteration 62: 0.0859420449355
Loss at the end of iteration 63: 0.0841727380512
Loss at the end of iteration 64: 0.0824398562584
Loss at the end of iteration 65: 0.0807426496661
Loss at the end of iteration 66: 0.0790803838214
Loss at the end of iteration 67: 0.077452339392
Loss at the end of iteration 68: 0.0758578118544
Loss at the end of iteration 69: 0.0742961111892
Loss at the end of iteration 70: 0.0727665615828
Loss at the end of iteration 71: 0.0712685011346
Loss at the end of iteration 72: 0.0698012815706
Loss at the end of iteration 73: 0.0683642679633
Loss at the end of iteration 74: 0.0669568384561
Loss at the end of iteration 75: 0.0655783839951
Loss at the end of iteration 76: 0.0642283080648
Loss at the end of iteration 77: 0.0629060264306
Loss at the end of iteration 78: 0.0616109668854
Loss at the end of iteration 79: 0.0603425690023
Loss at the end of iteration 80: 0.0591002838922
Loss at the end of iteration 81: 0.057883573966
Loss at the end of iteration 82: 0.0566919127019
Loss at the end of iteration 83: 0.0555247844179
Loss at the end of iteration 84: 0.0543816840484
Loss at the end of iteration 85: 0.0532621169257
Loss at the end of iteration 86: 0.0521655985659
Loss at the end of iteration 87: 0.0510916544593
Loss at the end of iteration 88: 0.050039819865
Loss at the end of iteration 89: 0.0490096396099
Loss at the end of iteration 90: 0.0480006678915
Loss at the end of iteration 91: 0.0470124680853
Loss at the end of iteration 92: 0.0460446125555
Loss at the end of iteration 93: 0.0450966824703
Loss at the end of iteration 94: 0.0441682676203
Loss at the end of iteration 95: 0.0432589662414
Loss at the end of iteration 96: 0.0423683848404
Loss at the end of iteration 97: 0.0414961380254
Loss at the end of iteration 98: 0.0406418483382
Loss at the end of iteration 99: 0.0483445666005
CROSS VALIDATION 19
Loss at the end of iteration 0: 36.3824242617
Loss at the end of iteration 1: 0.305698728599
Loss at the end of iteration 2: 0.299405244828
Loss at the end of iteration 3: 0.293241326326
Loss at the end of iteration 4: 0.287204305705
Loss at the end of iteration 5: 0.281291570493
Loss at the end of iteration 6: 0.275500562
Loss at the end of iteration 7: 0.269828774211
Loss at the end of iteration 8: 0.264273752706
Loss at the end of iteration 9: 0.258833093593
Loss at the end of iteration 10: 0.253504442468
Loss at the end of iteration 11: 0.248285493401
Loss at the end of iteration 12: 0.243173987932
Loss at the end of iteration 13: 0.238167714096
Loss at the end of iteration 14: 0.233264505469
Loss at the end of iteration 15: 0.228462240225
Loss at the end of iteration 16: 0.223758840221
Loss at the end of iteration 17: 0.219152270099
Loss at the end of iteration 18: 0.214640536401
Loss at the end of iteration 19: 0.21022168671
Loss at the end of iteration 20: 0.205893808804
Loss at the end of iteration 21: 0.201655029826
Loss at the end of iteration 22: 0.19750351548
Loss at the end of iteration 23: 0.193437469229
Loss at the end of iteration 24: 0.189455131524
Loss at the end of iteration 25: 0.185554779039
Loss at the end of iteration 26: 0.181734723929
Loss at the end of iteration 27: 0.177993313093
Loss at the end of iteration 28: 0.174328927466
Loss at the end of iteration 29: 0.170739981313
Loss at the end of iteration 30: 0.167224921547
Loss at the end of iteration 31: 0.163782227053
Loss at the end of iteration 32: 0.160410408032
Loss at the end of iteration 33: 0.157108005355
Loss at the end of iteration 34: 0.153873589934
Loss at the end of iteration 35: 0.150705762101
Loss at the end of iteration 36: 0.147603151003
Loss at the end of iteration 37: 0.14456441401
Loss at the end of iteration 38: 0.141588236132
Loss at the end of iteration 39: 0.138673329451
Loss at the end of iteration 40: 0.135818432565
Loss at the end of iteration 41: 0.133022310039
Loss at the end of iteration 42: 0.130283751874
Loss at the end of iteration 43: 0.127601572979
Loss at the end of iteration 44: 0.124974612663
Loss at the end of iteration 45: 0.122401734129
Loss at the end of iteration 46: 0.119881823985
Loss at the end of iteration 47: 0.117413791759
Loss at the end of iteration 48: 0.114996569429
Loss at the end of iteration 49: 0.112629110962
Loss at the end of iteration 50: 0.110310391858
Loss at the end of iteration 51: 0.108039408711
Loss at the end of iteration 52: 0.105815178769
Loss at the end of iteration 53: 0.103636739515
Loss at the end of iteration 54: 0.101503148246
Loss at the end of iteration 55: 0.0994134816678
Loss at the end of iteration 56: 0.0973668354931
Loss at the end of iteration 57: 0.0953623240521
Loss at the end of iteration 58: 0.093399079908
Loss at the end of iteration 59: 0.0914762534824
Loss at the end of iteration 60: 0.0895930126873
Loss at the end of iteration 61: 0.087748542565
Loss at the end of iteration 62: 0.0859420449355
Loss at the end of iteration 63: 0.0841727380512
Loss at the end of iteration 64: 0.0824398562584
Loss at the end of iteration 65: 0.0807426496661
Loss at the end of iteration 66: 0.0790803838214
Loss at the end of iteration 67: 0.077452339392
Loss at the end of iteration 68: 0.0758578118544
Loss at the end of iteration 69: 0.0742961111892
Loss at the end of iteration 70: 0.0727665615828
Loss at the end of iteration 71: 0.0712685011346
Loss at the end of iteration 72: 0.0698012815706
Loss at the end of iteration 73: 0.0683642679633
Loss at the end of iteration 74: 0.0669568384561
Loss at the end of iteration 75: 0.0655783839951
Loss at the end of iteration 76: 0.0642283080648
Loss at the end of iteration 77: 0.0629060264306
Loss at the end of iteration 78: 0.0616109668854
Loss at the end of iteration 79: 0.0603425690023
Loss at the end of iteration 80: 0.0591002838922
Loss at the end of iteration 81: 0.057883573966
Loss at the end of iteration 82: 0.0566919127019
Loss at the end of iteration 83: 0.0555247844179
Loss at the end of iteration 84: 0.0543816840484
Loss at the end of iteration 85: 0.0532621169257
Loss at the end of iteration 86: 0.0521655985659
Loss at the end of iteration 87: 0.0510916544593
Loss at the end of iteration 88: 0.050039819865
Loss at the end of iteration 89: 0.0490096396099
Loss at the end of iteration 90: 0.0480006678915
Loss at the end of iteration 91: 0.0470124680853
Loss at the end of iteration 92: 0.0460446125555
Loss at the end of iteration 93: 0.0450966824703
Loss at the end of iteration 94: 0.0441682676203
Loss at the end of iteration 95: 0.0432589662414
Loss at the end of iteration 96: 0.0423683848404
Loss at the end of iteration 97: 0.0414961380254
Loss at the end of iteration 98: 0.0406418483382
Loss at the end of iteration 99: 0.0483445666005
Learning rate: 0.0001, lambda: 1.0, Accuracy: 0.95
